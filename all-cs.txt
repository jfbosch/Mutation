// Program.cs
// ------------------------------



// CognitiveSupport\AudioRecorder.cs
// ------------------------------

using NAudio.Wave;
using NAudio.Lame;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;

namespace CognitiveSupport
{
	public class AudioRecorder : IDisposable
	{
		private WaveInEvent waveIn;
		private LameMP3FileWriter mp3Writer;

		public void StartRecording(
			int captureDeviceIndex,
			string outputFile)
		{
			waveIn = new WaveInEvent();
			waveIn.DeviceNumber = captureDeviceIndex;
			
			// Debugging exception to show the name.
			//throw new Exception("Device Index " + captureDeviceIndex + "   " + WaveInEvent.GetCapabilities(captureDeviceIndex).ProductName);

			mp3Writer = new LameMP3FileWriter(outputFile, waveIn.WaveFormat, LAMEPreset.STANDARD);

			waveIn.DataAvailable += (sender, e) =>
			{
				mp3Writer.Write(e.Buffer, 0, e.BytesRecorded);
			};

			waveIn.RecordingStopped += (sender, e) =>
			{
				Dispose();
			};

			waveIn.StartRecording();
		}

		public void StopRecording()
		{
			if (waveIn != null)
			{
				waveIn.StopRecording();
			}
		}

		public void Dispose()
		{
			mp3Writer?.Dispose();
			mp3Writer = null;
			waveIn?.Dispose();
			waveIn = null;
		}
	}

}


// CognitiveSupport\Enums.cs
// ------------------------------

namespace CognitiveSupport;

public enum SpeechToTextServices
{
	None = 0,
	OpenAiWhisper = 1,
	Deepgram = 2,
}


// CognitiveSupport\ILlmService.cs
// ------------------------------

using OpenAI.ObjectModels.RequestModels;

namespace CognitiveSupport;

public interface ILlmService
{
	Task<string> CreateChatCompletion(IList<ChatMessage> messages, string llmModelName, decimal temperature = 0.7M);
}


// CognitiveSupport\ITextToSpeechService.cs
// ------------------------------

namespace CognitiveSupport;

public interface ITextToSpeechService
{
	void SpeakText(string text);
}


// CognitiveSupport\LlmService.cs
// ------------------------------

using OpenAI;
using OpenAI.Interfaces;
using OpenAI.Managers;
using OpenAI.ObjectModels.RequestModels;

namespace CognitiveSupport;

public class LlmService : ILlmService
{
	private readonly string ApiKey;
	private readonly string Endpoint;
	private readonly object _lock = new object();
	private readonly Dictionary<string, IOpenAIService> _openAIServices;


	public LlmService(
		string apiKey,
		string azureResourceName,
		List<LlmSettings.ModelDeploymentIdMap> modelDeploymentIdMaps)
	{
		ApiKey = apiKey ?? throw new ArgumentNullException(nameof(apiKey));
		if (modelDeploymentIdMaps is null || !modelDeploymentIdMaps.Any())
			throw new ArgumentNullException(nameof(modelDeploymentIdMaps));

		_openAIServices = new Dictionary<string, IOpenAIService>();
		foreach (var map in modelDeploymentIdMaps)
		{
			OpenAiOptions options = new OpenAiOptions
			{
				ApiKey = apiKey,
				ResourceName = azureResourceName,
				ProviderType = ProviderType.Azure,
				DeploymentId = map.DeploymentId,
			};
			HttpClient httpClient = new HttpClient();
			httpClient.Timeout = TimeSpan.FromSeconds(60);
			_openAIServices[map.ModelName] = new OpenAIService(options, httpClient);
		}
	}

	public async Task<string> CreateChatCompletion(
		IList<ChatMessage> messages,
		string llmModelName,
		decimal temperature = 0.7m)
	{
		if (!_openAIServices.ContainsKey(llmModelName))
			throw new ArgumentException($"{llmModelName} is not one of the configured models. The following are the available, configured models: {string.Join(",", _openAIServices.Keys)}", nameof(llmModelName));

		var service = _openAIServices[llmModelName];
		var response = await service.ChatCompletion.CreateCompletion(new ChatCompletionCreateRequest
		{
			Messages = messages,
			Model = llmModelName,
			Temperature = (float)temperature,
		});
		if (response.Successful)
		{
			return response.Choices.First().Message.Content;
		}
		else
		{
			if (response.Error == null)
			{
				throw new Exception("Unknown Error");
			}
			return $"Error converting speech to text: {response.Error.Code} {response.Error.Message}";
		}
	}
}


// CognitiveSupport\TextFormatter.cs
// ------------------------------

using CognitiveSupport.Extensions;
using System.Text.RegularExpressions;
using static CognitiveSupport.LlmSettings;
using static CognitiveSupport.LlmSettings.TranscriptFormatRule;

namespace CognitiveSupport
{
	public static class TextFormatter
	{
		public static string FormatWithRules(
			this string text,
			List<LlmSettings.TranscriptFormatRule> rules)
		{
			if (text is null) return text;
			if (rules is null) throw new ArgumentNullException(nameof(rules));

			text = text.FixNewLines();

			foreach (var rule in rules)
				text = FormatWithRule(text, rule);

			string[] lines = text.Split(Environment.NewLine, StringSplitOptions.TrimEntries);
			lines = CleanLines(lines);
			text = string.Join(Environment.NewLine, lines);

			return text;
		}

		public static string CleanupPunctuation(
			this string text)
		{
			if (text is null) return text;

			string[] deduplications = new[]
			{
				".",
				",",
				"?",
				"!",
				":",
				";",
			};

			text = text.FixNewLines();
			int counter = 0;
			var lines = text.Split(Environment.NewLine, StringSplitOptions.TrimEntries)
				.ToDictionary(k => counter++, v => v);

			foreach (var dup in deduplications)
			{
				// this will replace the pattern with a single instance of the char in "dup".
				// Eg. If the dup char is ".", then ".." and ". ." wil be replaced with a single ".", but only if it is after a word, and before a word or end of line.
				string pattern = @$"(?<=\w)[.,]?[{dup}][ ,.]?[{dup}]?(?=\w|$)";

				foreach (int key in lines.Keys)
				{
					lines[key]  = Regex.Replace(lines[key], pattern, $"{dup} ");
				}
			}

			text = string.Join(Environment.NewLine, lines.Values);

			return text;
		}

		public static string[] CleanLines(
			this string[] input)
		{
			List<string> output = new(input.Length);
			foreach (string inLine in input)
			{
				string outLine = CleanLine(inLine);
				output.Add(outLine);
			}
			return output.ToArray();
		}

		private static string CleanLine(
			string line)
		{
			//line = line.RemovePrefix(", ");
			//line = line.RemovePrefix(". ");
			//line = line.RemovePrefix("; ");


			//line = line.Replace("- , ", "- ");
			//line = line.Replace("- . ", "- ");
			//line = line.Replace("- ; ", "- ");

			//line = line.Replace(", : ,", ":");
			//line = line.Replace(". : .", ":");
			//line = line.Replace(". : ,", ":");
			//line = line.Replace(", : .", ":");

			return line;
		}

		public static string FormatWithRule(
			string text,
			TranscriptFormatRule rule)
		{
			if (text is null) return text;
			if (rule is null) throw new ArgumentNullException(nameof(rule));

			RegexOptions regexOptions = RegexOptions.None;
			if (!rule.CaseSensitive)
				regexOptions = RegexOptions.IgnoreCase;

			switch (rule.MatchType)
			{
				case MatchTypeEnum.Plain:
					var comparison = StringComparison.InvariantCultureIgnoreCase;
					if (rule.CaseSensitive)
						comparison = StringComparison.InvariantCulture;

					text = text.Replace(rule.Find, rule.ReplaceWith, comparison);
					break;
				case MatchTypeEnum.RegEx:
					text = Regex.Replace(text, rule.Find, rule.ReplaceWith, regexOptions);
					break;
				case MatchTypeEnum.Smart:
					string pattern = $@"(\b|^)([.,]?)([ ]*{rule.Find}[.,]?[ ]*)(\b|$)";
					string replacement = $"$1$2{rule.ReplaceWith}$4";
					text = Regex.Replace(text, pattern, replacement, regexOptions);

					break;
				default:
					throw new NotImplementedException($"The MatchType {rule.MatchType}: {(int)rule.MatchType} is not implemented.");
			}

			return text;
		}

		public static string RemoveSubstrings(
			this string text,
			params string[] substringsToRemove)
		{
			if (text is null) return text;
			if (substringsToRemove is null || !substringsToRemove.Any())
				throw new ArgumentNullException(nameof(substringsToRemove));

			foreach (var substring in substringsToRemove)
			{
				text = text.Replace(substring, "");
			}

			return text;
		}
	}
}



// CognitiveSupport\TextToSpeechService.cs
// ------------------------------

using System.Speech.Synthesis;

namespace CognitiveSupport
{
	public class TextToSpeechService : ITextToSpeechService
	{
		private readonly object _lock = new object();

		public void SpeakText(
			string text)
		{
			using (SpeechSynthesizer synth = new SpeechSynthesizer())
			{
				synth.SetOutputToDefaultAudioDevice();
				synth.Rate = 8;

				synth.Speak(text);

				//var voices = synth.GetInstalledVoices();
				//string voiceNames = "";
				//foreach (var voice in voices)
				//	voiceNames += voice.VoiceInfo.Name + Environment.NewLine;
				//MessageBox.Show(voiceNames, "Available Voices");
			}

		}
	}
}


// CognitiveSupport\DeepgramSpeechToTextService.cs
// ------------------------------

using CognitiveSupport.Extensions;
using Deepgram.Models.Listen.v1.REST;
using Polly;
using Polly.Contrib.WaitAndRetry;
using Polly.Timeout;
using System.Text.RegularExpressions;

namespace CognitiveSupport;

public class DeepgramSpeechToTextService : ISpeechToTextService
{
	private readonly string _modelId;
	private readonly object _lock = new object();
	private readonly Deepgram.Clients.Interfaces.v1.IListenRESTClient _deepgramClient;

	public DeepgramSpeechToTextService(
		Deepgram.Clients.Interfaces.v1.IListenRESTClient deepgramClient,
		string modelId)
	{
		_deepgramClient = deepgramClient ?? throw new ArgumentNullException(nameof(deepgramClient));
		_modelId = modelId ?? throw new ArgumentNullException(nameof(modelId), "Check your Whisper API provider's documentation for supported modelIds. On OpenAI, it's something like 'whisper-1'. On Groq, it's something like 'whisper-large-v3'.");
	}

	public async Task<string> ConvertAudioToText(
		string speechToTextPrompt,
		string audioffilePath,
		CancellationToken overallCancellationToken)
	{
		if (string.IsNullOrEmpty(audioffilePath))
			throw new ArgumentException($"'{nameof(audioffilePath)}' cannot be null or empty.", nameof(audioffilePath));

		List<string> keywords = ParseKeywords(speechToTextPrompt);
		var audioBytes = await File.ReadAllBytesAsync(audioffilePath).ConfigureAwait(false);
		const string AttemptKey = "Attempt";

		var delay = Backoff.LinearBackoff(TimeSpan.FromMilliseconds(500), retryCount: 3, factor: 1);
		var retryPolicy = Policy
			.Handle<HttpRequestException>()
			.Or<TimeoutRejectedException>()
			.Or<TaskCanceledException>()
				.WaitAndRetryAsync(
					delay,
					onRetry: (exception, timeSpan, attemptNumber, context) =>
					{
						int attempt = context.ContainsKey(AttemptKey) ? (int)context[AttemptKey] : 1;
						context[AttemptKey] = ++attempt;
					}
				);

		var context = new Context();
		context[AttemptKey] = 1;
		var response = await retryPolicy.ExecuteAsync(async (context, overallToken) =>
		{
			int attempt = context.ContainsKey(AttemptKey) ? (int)context[AttemptKey] : 1;
			var thisTryCts = new CancellationTokenSource(TimeSpan.FromSeconds(5 * attempt));
			using var linkedCts = CancellationTokenSource.CreateLinkedTokenSource(overallToken, thisTryCts.Token);

			if (attempt > 0)
				this.Beep(attempt);

			return await TranscribeViaDeepgram(keywords, audioBytes, linkedCts).ConfigureAwait(false);
		}, context, overallCancellationToken).ConfigureAwait(false);

		return response.Results.Channels?.FirstOrDefault()?.Alternatives?.FirstOrDefault().Transcript
			?? "(no transcript available)";
	}

	private async Task<SyncResponse> TranscribeViaDeepgram(
		List<string> keywords,
		byte[] audioBytes,
		CancellationTokenSource cancellationTokenSource)
	{
		var response = await _deepgramClient.TranscribeFile(
		  audioBytes,
		  new PreRecordedSchema()
		  {
			  Model = _modelId,
			  Keywords = keywords,

			  Punctuate = true,
			  FillerWords = false,
			  Measurements = true,
			  SmartFormat = true,
			  //Diarize = true,
		  }, cancellationTokenSource = cancellationTokenSource);
		return response;
	}

	private static List<string> ParseKeywords(string speechToTextPrompt)
	{
		if (speechToTextPrompt == null)
			speechToTextPrompt = string.Empty;

		string pattern = @"(?<=\bkeywords:\s*).*?(?=\.)";
		Match match = Regex.Match(speechToTextPrompt, pattern, RegexOptions.IgnoreCase);
		if (match.Success)
		{
			string keywordsString = match.Value.Trim();
			var keywords = keywordsString.Split(",", StringSplitOptions.TrimEntries | StringSplitOptions.RemoveEmptyEntries)
				.Select(n =>
				{
					//If the keyword already contains an intensifier, return it as is. Else add an intensifier of 1. 
					//https://developers.deepgram.com/docs/keywords
					return n.IndexOf(":") > 0 ?
						n :
						$"{n}1";
				})
				.ToList();
			return keywords;
		}
		else
			return null;
	}
}


// CognitiveSupport\IOcrService.cs
// ------------------------------

namespace CognitiveSupport;

public interface IOcrService
{
	Task<string> ExtractText(Stream imageStream, CancellationToken overallCancellationToken);
}


// CognitiveSupport\ISpeechToTextService.cs
// ------------------------------

namespace CognitiveSupport;

public interface ISpeechToTextService
{
	Task<string> ConvertAudioToText(string speechToTextPrompt, string audioffilePath, CancellationToken overallCancellationToken);
}


// CognitiveSupport\OcrService.cs
// ------------------------------

using CognitiveSupport.Extensions;
using Microsoft.Azure.CognitiveServices.Vision.ComputerVision;
using Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models;
using Polly;
using Polly.Contrib.WaitAndRetry;
using Polly.Timeout;
using System.Text;

namespace CognitiveSupport;

public class OcrService : IOcrService
{
	private string SubscriptionKey { get; init; }
	private string Endpoint { get; init; }
	private ComputerVisionClient ComputerVisionClient { get; init; }
	private readonly object _lock = new();

	public OcrService(
		string? subscriptionKey,
		string? endpoint)
	{
		SubscriptionKey = subscriptionKey ?? throw new ArgumentNullException(nameof(subscriptionKey));
		Endpoint = endpoint ?? throw new ArgumentNullException(nameof(endpoint));
		ComputerVisionClient = CreateComputerVisionClient(Endpoint, SubscriptionKey);
	}

	public async Task<string> ExtractText(
		Stream imageStream,
		CancellationToken overallCancellationToken)
	{
		return await ReadFile(imageStream, overallCancellationToken).ConfigureAwait(false);
	}

	private ComputerVisionClient CreateComputerVisionClient(
		string endpoint,
		string key)
	{
		ComputerVisionClient client =
			new ComputerVisionClient(new ApiKeyServiceClientCredentials(key))
			{
				Endpoint = endpoint
			};
		return client;
	}

	private async Task<string> ReadFile(
		Stream imageStream,
		CancellationToken overallCancellationToken)
	{
		const string AttemptKey = "Attempt";
		var delay = Backoff.LinearBackoff(TimeSpan.FromMilliseconds(500), retryCount: 3, factor: 1);
		var retryPolicy = Policy
			.Handle<HttpRequestException>()
			.Or<TimeoutRejectedException>()
			.Or<TaskCanceledException>()
			.WaitAndRetryAsync(
				delay,
				onRetry: (exception, timeSpan, attemptNumber, context) =>
				{
					int attempt = context.ContainsKey(AttemptKey) ? (int)context[AttemptKey] : 1;
					context[AttemptKey] = ++attempt;
				}
			);

		var context = new Context();
		context[AttemptKey] = 1;

		string response = await retryPolicy.ExecuteAsync(async (context, overallToken) =>
		{
			int attempt = context.ContainsKey(AttemptKey) ? (int)context[AttemptKey] : 1;
			var thisTryCts = new CancellationTokenSource(TimeSpan.FromSeconds(7.5 * attempt));
			using var linkedCts = CancellationTokenSource.CreateLinkedTokenSource(overallToken, thisTryCts.Token);

			if (attempt > 0)
				this.Beep(attempt);

			return await ReadFileInternal(imageStream, linkedCts.Token).ConfigureAwait(false);

		}, context, overallCancellationToken).ConfigureAwait(false);

		return response;
	}


	private async Task<string> ReadFileInternal(
		Stream imageStream,
		CancellationToken cancellationToken)
	{
		const int delayMilliseconds = 500;
		const int numberOfCharsInOperationId = 36;

		Log("----------------------------------------------------------");
		Log("READ FROM file");

		var textHeaders = await this.ComputerVisionClient.ReadInStreamAsync(imageStream, cancellationToken: cancellationToken).ConfigureAwait(false);

		string operationLocation = textHeaders.OperationLocation;
		await Task.Delay(delayMilliseconds, cancellationToken).ConfigureAwait(false);
		Log($"operationLocation {operationLocation}");

		string operationId = operationLocation.Substring(operationLocation.Length - numberOfCharsInOperationId);

		var results = await GetReadOperationResultAsync(operationId, cancellationToken).ConfigureAwait(false);

		return ExtractTextFromResults(results);
	}

	private async Task<ReadOperationResult> GetReadOperationResultAsync(string operationId, CancellationToken cancellationToken)
	{
		ReadOperationResult results;
		do
		{
			results = await this.ComputerVisionClient.GetReadResultAsync(Guid.Parse(operationId), cancellationToken).ConfigureAwait(false);
		}
		while (results.Status == OperationStatusCodes.Running || results.Status == OperationStatusCodes.NotStarted);

		return results;
	}

	private string ExtractTextFromResults(ReadOperationResult results)
	{
		StringBuilder sb = new();
		var textUrlFileResults = results.AnalyzeResult.ReadResults;
		foreach (ReadResult page in textUrlFileResults)
		{
			foreach (Line line in page.Lines)
			{
				Log(line.Text);
				sb.AppendLine(line.Text);
			}
		}
		Log(string.Empty);

		return sb.ToString();
	}

	private void Log(string message)
	{
		// Replace this with a proper logging mechanism
		Console.WriteLine(message);
	}
}


// CognitiveSupport\WhisperSpeechToTextService.cs
// ------------------------------

using CognitiveSupport.Extensions;
using OpenAI.Interfaces;
using OpenAI.ObjectModels;
using OpenAI.ObjectModels.RequestModels;
using Polly;
using Polly.Contrib.WaitAndRetry;
using Polly.Timeout;

namespace CognitiveSupport;

public class WhisperSpeechToTextService : ISpeechToTextService
{
	private readonly string _modelId;
	private readonly object _lock = new object();
	private readonly IOpenAIService _openAIService;

	public WhisperSpeechToTextService(
		IOpenAIService openAIService,
		string modelId)
	{
		_openAIService = openAIService ?? throw new ArgumentNullException(nameof(openAIService));
		_modelId = modelId ?? throw new ArgumentNullException(nameof(modelId), "Check your Whisper API provider's documentation for supported modelIds. On OpenAI, it's something like 'whisper-1'. On Groq, it's something like 'whisper-large-v3'.");
	}

	public async Task<string> ConvertAudioToText(
		string speechToTextPrompt,
		string audioffilePath,
		CancellationToken overallCancellationToken)
	{
		if (string.IsNullOrEmpty(audioffilePath))
			throw new ArgumentException($"'{nameof(audioffilePath)}' cannot be null or empty.", nameof(audioffilePath));

		var audioBytes = await File.ReadAllBytesAsync(audioffilePath).ConfigureAwait(false);
		const string AttemptKey = "Attempt";

		var delay = Backoff.LinearBackoff(TimeSpan.FromMilliseconds(500), retryCount: 3, factor: 1);
		var retryPolicy = Policy
			.Handle<HttpRequestException>()
			.Or<TimeoutRejectedException>()
			.Or<TaskCanceledException>()
				.WaitAndRetryAsync(
					delay,
					onRetry: (exception, timeSpan, attemptNumber, context) =>
					{
						int attempt = context.ContainsKey(AttemptKey) ? (int)context[AttemptKey] : 1;
						context[AttemptKey] = ++attempt;
					}
				);

		var context = new Context();
		context[AttemptKey] = 1;
		
		var response = await retryPolicy.ExecuteAsync(async (context, overallToken) =>
		{
			int attempt = context.ContainsKey(AttemptKey) ? (int)context[AttemptKey] : 1;
			var thisTryCts = new CancellationTokenSource(TimeSpan.FromSeconds(5 * attempt));
			using var linkedCts = CancellationTokenSource.CreateLinkedTokenSource(overallToken, thisTryCts.Token);

			if (attempt > 0)
				this.Beep(attempt);

			return await TranscribeViaWhisper(speechToTextPrompt, audioffilePath, audioBytes, linkedCts.Token).ConfigureAwait(false);
		}, context, overallCancellationToken).ConfigureAwait(false);

		if (response.Successful)
		{
			return response.Text;
		}
		else
		{
			if (response.Error == null)
			{
				throw new Exception("Unknown Error");
			}
			return $"Error converting speech to text: {response.Error.Code} {response.Error.Message}";
		}
	}

	private async Task<OpenAI.ObjectModels.ResponseModels.AudioCreateTranscriptionResponse> TranscribeViaWhisper(
		string speechToTextPrompt,
		string audioffilePath,
		byte[] audioBytes,
		CancellationToken cancellationToken)
	{
		return await _openAIService.Audio.CreateTranscription(new AudioCreateTranscriptionRequest
		{
			Prompt = speechToTextPrompt,
			FileName = Path.GetFileName(audioffilePath),
			File = audioBytes,
			Model = _modelId,
			ResponseFormat = StaticValues.AudioStatics.ResponseFormat.VerboseJson
		}, cancellationToken);
	}
}


// CognitiveSupport\Settings.cs
// ------------------------------

using System.Drawing;

namespace CognitiveSupport;

public class Settings
{
	public string UserInstructions { get; set; }

	public AudioSettings AudioSettings { get; set; }
	public AzureComputerVisionSettings AzureComputerVisionSettings { get; set; }
	public SpeetchToTextSettings SpeetchToTextSettings { get; set; }
	public LlmSettings LlmSettings { get; set; }
	public TextToSpeechSettings TextToSpeechSettings { get; set; }

	public MainWindowUiSettings MainWindowUiSettings { get; set; } = new MainWindowUiSettings();

	public HotKeyRouterSettings HotKeyRouterSettings { get; set; } = new HotKeyRouterSettings();

	public Settings()
	{
	}

	public Settings(string userInstructions, AudioSettings audioSettings, AzureComputerVisionSettings azureComputerVisionSettings, SpeetchToTextSettings speetchToTextSettings, LlmSettings llmSettings, TextToSpeechSettings textToSpeechSettings, MainWindowUiSettings mainWindowUiSettings, HotKeyRouterSettings hotKeyRouterSettings)
	{
		UserInstructions = userInstructions;
		AudioSettings = audioSettings;
		AzureComputerVisionSettings = azureComputerVisionSettings;
		SpeetchToTextSettings = speetchToTextSettings;
		LlmSettings = llmSettings;
		TextToSpeechSettings = textToSpeechSettings;
		MainWindowUiSettings = mainWindowUiSettings;
		HotKeyRouterSettings = hotKeyRouterSettings;
	}
}

public class AudioSettings
{
	public string ActiveCaptureDeviceFullName { get; set; }
	public string MicrophoneToggleMuteHotKey { get; set; }

	public AudioSettings()
	{
	}

	public AudioSettings(string microphoneToggleMuteHotKey)
	{
		MicrophoneToggleMuteHotKey = microphoneToggleMuteHotKey;
	}
}

public class MainWindowUiSettings
{
	public Point WindowLocation { get; set; }
	public Size WindowSize { get; set; }

	public MainWindowUiSettings()
	{
	}

	public MainWindowUiSettings(Point windowLocation, Size windowSize)
	{
		WindowLocation = windowLocation;
		WindowSize = windowSize;
	}
}

public class AzureComputerVisionSettings
{
	public string ScreenshotHotKey { get; set; }
	public string ScreenshotOcrHotKey { get; set; }
	public string OcrHotKey { get; set; }
	public string ApiKey { get; set; }
	public string Endpoint { get; set; }

	public AzureComputerVisionSettings()
	{
	}

	public AzureComputerVisionSettings(string screenshotHotKey, string screenshotOcrHotKey, string ocrHotKey, string apiKey, string endpoint)
	{
		ScreenshotHotKey = screenshotHotKey;
		ScreenshotOcrHotKey = screenshotOcrHotKey;
		OcrHotKey = ocrHotKey;
		ApiKey = apiKey;
		Endpoint = endpoint;
	}
}

public class SpeetchToTextSettings
{
	public SpeechToTextServices Service { get; set; }
	public string SpeechToTextHotKey { get; set; }
	public string ApiKey { get; set; }
	public string BaseDomain { get; set; }
	public string ModelId { get; set; }
	public string TempDirectory { get; set; }
	public string SpeechToTextPrompt { get; set; }

	public SpeetchToTextSettings()
	{
	}

	public SpeetchToTextSettings(SpeechToTextServices service, string speechToTextHotKey, string apiKey, string baseDomain, string modelId, string tempDirectory, string speechToTextPrompt)
	{
		Service = service;
		SpeechToTextHotKey = speechToTextHotKey;
		ApiKey = apiKey;
		BaseDomain = baseDomain;
		ModelId = modelId;
		TempDirectory = tempDirectory;
		SpeechToTextPrompt = speechToTextPrompt;
	}
}

public class LlmSettings
{
	public string ApiKey { get; set; }
	public string ResourceName { get; set; }
	public List<ModelDeploymentIdMap> ModelDeploymentIdMaps { get; set; }
	public List<TranscriptFormatRule> TranscriptFormatRules { get; set; }
	public string FormatTranscriptPrompt { get; set; }
	public string ReviewTranscriptPrompt { get; set; }

	public LlmSettings()
	{
		ModelDeploymentIdMaps = new List<ModelDeploymentIdMap>();
		TranscriptFormatRules = new List<TranscriptFormatRule>();
	}

	public LlmSettings(string apiKey, string resourceName, List<ModelDeploymentIdMap> modelDeploymentIdMaps, List<TranscriptFormatRule> transcriptFormatRules, string formatTranscriptPrompt, string reviewTranscriptPrompt)
	{
		ApiKey = apiKey;
		ResourceName = resourceName;
		ModelDeploymentIdMaps = modelDeploymentIdMaps;
		TranscriptFormatRules = transcriptFormatRules;
		FormatTranscriptPrompt = formatTranscriptPrompt;
		ReviewTranscriptPrompt = reviewTranscriptPrompt;
	}

	public class ModelDeploymentIdMap
	{
		public string ModelName { get; set; }
		public string DeploymentId { get; set; }

		public ModelDeploymentIdMap()
		{
		}

		public ModelDeploymentIdMap(string modelName, string deploymentId)
		{
			ModelName = modelName;
			DeploymentId = deploymentId;
		}
	}

	public class TranscriptFormatRule
	{
		public string Find { get; set; }
		public string ReplaceWith { get; set; }
		public bool CaseSensitive { get; set; }
		public MatchTypeEnum MatchType { get; set; }

		public TranscriptFormatRule()
		{
		}

		public TranscriptFormatRule(string find, string replaceWith, bool caseSensitive, MatchTypeEnum matchType)
		{
			Find = find;
			ReplaceWith = replaceWith;
			CaseSensitive = caseSensitive;
			MatchType = matchType;
		}

		public enum MatchTypeEnum
		{
			Plain = 1,
			RegEx = 2,
			Smart = 3,
		}
	}
}

public class TextToSpeechSettings
{
	public string TextToSpeechHotKey { get; set; }

	public TextToSpeechSettings()
	{
	}

	public TextToSpeechSettings(string textToSpeechHotKey)
	{
		TextToSpeechHotKey = textToSpeechHotKey;
	}
}

public class HotKeyRouterSettings
{
	public List<HotKeyRouterMap> Mappings { get; set; } = new List<HotKeyRouterMap>();

	public HotKeyRouterSettings()
	{
	}

	public HotKeyRouterSettings(List<HotKeyRouterMap> mappings)
	{
		Mappings = mappings;
	}

	public class HotKeyRouterMap
	{
		public string FromHotKey { get; set; }
		public string ToHotKey { get; set; }

		public HotKeyRouterMap(
			string fromHotKey,
			string toHotKey)
		{
			FromHotKey = fromHotKey ?? throw new ArgumentNullException(nameof(fromHotKey));
			ToHotKey = toHotKey ?? throw new ArgumentNullException(nameof(toHotKey));
		}
	}
}



// CognitiveSupport\Extensions\ObjectExtensions.cs
// ------------------------------

namespace CognitiveSupport.Extensions;

public static class ObjectExtensions
{
	public static void Beep(
		this object caller,
		int attempt)
	{
#pragma warning disable CA1416 // Validate platform compatibility
		Console.Beep(400 + (100 * attempt), 100);
#pragma warning restore CA1416 // Validate platform compatibility
	}

}


// CognitiveSupport\Extensions\StringExtensions.cs
// ------------------------------

namespace CognitiveSupport.Extensions;

public static class StringExtensions
{
	/// <summary>
	/// Converts any partial new lines and carriage returns in the given string to the system's new line representation.
	/// If the input string contains only '\n' or '\r', they are replaced with the appropriate new line string for the system.
	/// If a correct new line for the system already exists, it remains unchanged.
	/// </summary>
	/// <param name="text">The input string that may contain partial new lines or carriage returns.</param>
	/// <returns>A new string with all partial new lines and carriage returns replaced by the system's new line representation, or null if the input is null.</returns>
	public static string FixNewLines(
		this string text)
	{
		if (text is null) return text;

		// Replace isolated "\r" with "\n"
		text = text.Replace("\r\n", "\n");
		text = text.Replace("\r", "\n");

		text = text.Replace("\n", Environment.NewLine);

		return text;
	}

}



// Mutation\Constants.cs
// ------------------------------

namespace Mutation
{
	internal static class Constants
	{
		internal const string SessionsDirectoryName = "Sessions";
	}
}



// Mutation\DictationInsertOption.cs
// ------------------------------

using System.ComponentModel;

namespace Mutation;

public enum DictationInsertOption
{
	[Description("Don't insert into 3rd party application")]
	DoNotInsert,

	[Description("Send keys to 3rd party application")]
	SendKeys,

	[Description("Paste into 3rd party application")]
	Paste
}




// Mutation\Hotkey.cs
// ------------------------------

using System.ComponentModel;
using System.Runtime.InteropServices;
using System.Xml.Serialization;

namespace Mutation
{
	// http://bloggablea.wordpress.com/2007/05/01/global-hotkeys-with-net/
	public class Hotkey : IMessageFilter
	{
		#region Interop

		[DllImport("user32.dll", SetLastError = true)]
		private static extern int RegisterHotKey(IntPtr hWnd, int id, uint fsModifiers, Keys vk);

		[DllImport("user32.dll", SetLastError = true)]
		private static extern int UnregisterHotKey(IntPtr hWnd, int id);

		private const uint WM_HOTKEY = 0x312;

		private const uint MOD_ALT = 0x1;
		private const uint MOD_CONTROL = 0x2;
		private const uint MOD_SHIFT = 0x4;
		private const uint MOD_WIN = 0x8;

		private const uint ERROR_HOTKEY_ALREADY_REGISTERED = 1409;

		#endregion

		private static int currentID;
		private const int maximumID = 0xBFFF;

		private Keys keyCode;
		private bool shift;
		private bool control;
		private bool alt;
		private bool windows;

		[XmlIgnore]
		private int id;
		[XmlIgnore]
		private bool registered;
		[XmlIgnore]
		private Control windowControl;

		public event HandledEventHandler Pressed;

		public Hotkey()
			: this(Keys.None, false, false, false, false)
		{
			// No work done here!
		}

		public Hotkey(Keys keyCode, bool shift, bool control, bool alt, bool windows)
		{
			// Assign properties
			this.KeyCode = keyCode;
			this.Shift = shift;
			this.Control = control;
			this.Alt = alt;
			this.Windows = windows;

			// Register us as a message filter
			Application.AddMessageFilter(this);
		}

		~Hotkey()
		{
			// Unregister the hotkey if necessary
			if (this.Registered)
			{
				this.Unregister();
			}
		}

		public Hotkey Clone()
		{
			// Clone the whole object
			return new Hotkey(this.keyCode, this.shift, this.control, this.alt, this.windows);
		}

		public bool GetCanRegister(Control windowControl)
		{
			// Handle any exceptions: they mean "no, you can't register" :)
			try
			{
				// Attempt to register
				if (!this.Register(windowControl))
				{
					return false;
				}

				// Unregister and say we managed it
				this.Unregister();
				return true;
			}
			catch (Win32Exception)
			{
				return false;
			}
			catch (NotSupportedException)
			{
				return false;
			}
		}

		public bool Register(Control windowControl)
		{
			// Check that we have not registered
			if (this.registered)
			{
				throw new NotSupportedException("You cannot register a hotkey that is already registered");
			}

			// We can't register an empty hotkey
			if (this.Empty)
			{
				throw new NotSupportedException("You cannot register an empty hotkey");
			}

			// Get an ID for the hotkey and increase current ID
			this.id = Hotkey.currentID;
			Hotkey.currentID = Hotkey.currentID + 1 % Hotkey.maximumID;

			// Translate modifier keys into unmanaged version
			uint modifiers =
				(this.Alt ? Hotkey.MOD_ALT : 0)
				| (this.Control ? Hotkey.MOD_CONTROL : 0)
				| (this.Shift ? Hotkey.MOD_SHIFT : 0)
				| (this.Windows ? Hotkey.MOD_WIN : 0);

			// Register the hotkey
			if (Hotkey.RegisterHotKey(windowControl.Handle, this.id, modifiers, keyCode) == 0)
			{
				// Is the error that the hotkey is registered?
				if (Marshal.GetLastWin32Error() == ERROR_HOTKEY_ALREADY_REGISTERED)
					return false;
				else
					throw new Win32Exception();
			}

			// Save the control reference and register state
			this.registered = true;
			this.windowControl = windowControl;

			// We successfully registered
			return true;
		}

		public void Unregister()
		{
			// Check that we have registered
			if (!this.registered)
				throw new NotSupportedException("You cannot unregister a hotkey that is not registered");

			// It's possible that the control itself has died: in that case, no need to unregister!
			if (!this.windowControl.IsDisposed)
			{
				// Clean up after ourselves
				if (Hotkey.UnregisterHotKey(this.windowControl.Handle, this.id) == 0)
					throw new Win32Exception();
			}

			// Clear the control reference and register state
			this.registered = false;
			this.windowControl = null;
		}

		private void Reregister()
		{
			// Only do something if the key is already registered
			if (!this.registered)
			{ return; }

			// Save control reference
			Control windowControl = this.windowControl;

			// Unregister and then reregister again
			this.Unregister();
			this.Register(windowControl);
		}

		public bool PreFilterMessage(ref Message message)
		{
			// Only process WM_HOTKEY messages
			if (message.Msg != Hotkey.WM_HOTKEY)
			{ return false; }

			// Check that the ID is our key and we are registerd
			if (this.registered && (message.WParam.ToInt32() == this.id))
			{
				// Fire the event and pass on the event if our handlers didn't handle it
				return this.OnPressed();
			}
			else
			{ return false; }
		}

		private bool OnPressed()
		{
			// Fire the event if we can
			HandledEventArgs handledEventArgs = new HandledEventArgs(false);
			if (this.Pressed != null)
			{ this.Pressed(this, handledEventArgs); }

			// Return whether we handled the event or not
			return handledEventArgs.Handled;
		}

		public override string ToString()
		{
			// We can be empty
			if (this.Empty)
			{ return "(none)"; }

			// Build key name
			string keyName = Enum.GetName(typeof(Keys), this.keyCode); ;
			switch (this.keyCode)
			{
				case Keys.D0:
				case Keys.D1:
				case Keys.D2:
				case Keys.D3:
				case Keys.D4:
				case Keys.D5:
				case Keys.D6:
				case Keys.D7:
				case Keys.D8:
				case Keys.D9:
					// Strip the first character
					keyName = keyName.Substring(1);
					break;
				default:
					// Leave everything alone
					break;
			}

			// Build modifiers
			string modifiers = "";
			if (this.shift)
			{ modifiers += "Shift+"; }
			if (this.control)
			{ modifiers += "Control+"; }
			if (this.alt)
			{ modifiers += "Alt+"; }
			if (this.windows)
			{ modifiers += "Windows+"; }

			// Return result
			return modifiers + keyName;
		}

		public bool Empty
		{
			get { return this.keyCode == Keys.None; }
		}

		public bool Registered
		{
			get { return this.registered; }
		}

		public Keys KeyCode
		{
			get { return this.keyCode; }
			set
			{
				// Save and reregister
				this.keyCode = value;
				this.Reregister();
			}
		}

		public bool Shift
		{
			get { return this.shift; }
			set
			{
				// Save and reregister
				this.shift = value;
				this.Reregister();
			}
		}

		public bool Control
		{
			get { return this.control; }
			set
			{
				// Save and reregister
				this.control = value;
				this.Reregister();
			}
		}

		public bool Alt
		{
			get { return this.alt; }
			set
			{
				// Save and reregister
				this.alt = value;
				this.Reregister();
			}
		}

		public bool Windows
		{
			get { return this.windows; }
			set
			{
				// Save and reregister
				this.windows = value;
				this.Reregister();
			}
		}
	}
}



// Mutation\ISettingsManager.cs
// ------------------------------

using CognitiveSupport;

namespace Mutation;

public interface ISettingsManager
{
	void SaveSettingsToFile(Settings settings);
	void UpgradeSettings();
	Settings LoadAndEnsureSettings();
}


// Mutation\MessageForm.Designer.cs
// ------------------------------

namespace Mutation
{
	partial class MessageForm
	{
		/// <summary>
		/// Required designer variable.
		/// </summary>
		private System.ComponentModel.IContainer components = null;

		/// <summary>
		/// Clean up any resources being used.
		/// </summary>
		/// <param name="disposing">true if managed resources should be disposed; otherwise, false.</param>
		protected override void Dispose(bool disposing)
		{
			if (disposing && (components != null))
			{
				components.Dispose();
			}
			base.Dispose(disposing);
		}

		#region Windows Form Designer generated code

		/// <summary>
		/// Required method for Designer support - do not modify
		/// the contents of this method with the code editor.
		/// </summary>
		private void InitializeComponent()
		{
			this.components = new System.ComponentModel.Container();
			this.AutoScaleMode = System.Windows.Forms.AutoScaleMode.Font;
			this.ClientSize = new System.Drawing.Size(800, 450);
			this.Text = "MessageForm";
		}

		#endregion
	}
}


// Mutation\MessageForm.cs
// ------------------------------

using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Data;
using System.Drawing;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using System.Windows.Forms;

namespace Mutation
{
	public partial class MessageForm : Form
	{
		public MessageForm()
		{
			InitializeComponent();
		}
	}
}



// Mutation\Program.cs
// ------------------------------

using AudioSwitcher.AudioApi.CoreAudio;
using CognitiveSupport;
using Deepgram;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Hosting;
using OpenAI;
using OpenAI.Interfaces;
using OpenAI.Managers;

namespace Mutation;

internal static class Program
{
	[STAThread]
	static void Main()
	{
		// To customize application configuration such as set high DPI settings or default font,
		// see https://aka.ms/applicationconfiguration.

		Application.EnableVisualStyles();
		Application.SetCompatibleTextRenderingDefault(false);
		ApplicationConfiguration.Initialize();

		try
		{
			HostApplicationBuilder builder = CreateApplicationBuilder();
			using IHost host = builder.Build();

			using var serviceScope = host.Services.CreateScope();
			var services = serviceScope.ServiceProvider;
			var mainForm = services.GetRequiredService<MutationForm>();

			Application.Run(mainForm);
		}
		catch (Exception ex)
		{
			MessageBox.Show($"Error starting up: {ex.ToString()}");
		}
	}

	private static HostApplicationBuilder CreateApplicationBuilder()
	{
		HostApplicationBuilder builder = Host.CreateApplicationBuilder();

		var settingsManager = CreateSettingsManager();
		var settings = settingsManager.LoadAndEnsureSettings();
		builder.Services.AddSingleton<ISettingsManager>(settingsManager);
		builder.Services.AddSingleton<CognitiveSupport.Settings>(settings);

		builder.Services.AddSingleton<CoreAudioController>();

		builder.Services.AddSingleton<IOcrService>(
			new OcrService(settings.AzureComputerVisionSettings.ApiKey, settings.AzureComputerVisionSettings.Endpoint));

		builder.Services.AddSingleton<ILlmService>(
			new LlmService(
				settings.LlmSettings.ApiKey,
				settings.LlmSettings.ResourceName,
				settings.LlmSettings.ModelDeploymentIdMaps));


		const string OpenAiHttpClient = "openai-http-client";
		builder.Services.AddHttpClient(OpenAiHttpClient);

		builder.Services.AddSingleton<IOpenAIService>(x =>
		{
			string baseDomain = settings.SpeetchToTextSettings.BaseDomain?.Trim();
			if (baseDomain == "")
				baseDomain = null;

			OpenAiOptions options = new OpenAiOptions
			{
				ApiKey = settings.SpeetchToTextSettings.ApiKey,
				BaseDomain = baseDomain,
			};

			IHttpClientFactory httpClientFactory = x.GetRequiredService<IHttpClientFactory>();
			HttpClient httpClient = httpClientFactory.CreateClient(OpenAiHttpClient);
			return new OpenAIService(options, httpClient);
		});


		switch (settings.SpeetchToTextSettings.Service)
		{
			case SpeechToTextServices.OpenAiWhisper:
				AddWhisperSpeechToTextService(builder, settings);
				break;
			case SpeechToTextServices.Deepgram:
				AddDeepgramSpeechToTextService(builder, settings);
				break;
			default:
				throw new NotSupportedException($"The SpeetchToText service '{settings.SpeetchToTextSettings.Service}' is not supported.");
		}


		builder.Services.AddSingleton<ITextToSpeechService, TextToSpeechService>();

		builder.Services.AddSingleton<MutationForm>();

		return builder;
	}

	private static void AddWhisperSpeechToTextService(HostApplicationBuilder builder, Settings settings)
	{
		builder.Services.AddSingleton<ISpeechToTextService>(x =>
		{
			var openAIService = x.GetRequiredService<IOpenAIService>();

			return new WhisperSpeechToTextService(
				openAIService,
				settings.SpeetchToTextSettings.ModelId);
		});
	}

	private static void AddDeepgramSpeechToTextService(HostApplicationBuilder builder, Settings settings)
	{
		builder.Services.AddSingleton<ISpeechToTextService>(x =>
		{
			Deepgram.Clients.Interfaces.v1.IListenRESTClient deepgramClient = ClientFactory.CreateListenRESTClient(
				settings.SpeetchToTextSettings.ApiKey);

			return new DeepgramSpeechToTextService(
				deepgramClient,
				settings.SpeetchToTextSettings.ModelId);
		});
	}

	private static SettingsManager CreateSettingsManager()
	{
		try
		{
			string filePath = "Mutation.json";
			SettingsManager settingsManager = new SettingsManager(filePath);
			return settingsManager;
		}
		catch (Exception ex)
			when (ex.Message.ToLower().Contains("could not find the settings"))
		{
			//MessageBox.Show(this, $"Failed to load settings: {ex.Message}", "Unexpected error", MessageBoxButtons.OK, MessageBoxIcon.Error);
			throw;
		}
	}

	private static void BeepFail(int numberOfBeeps = 1)
	{
		for (int i = 0; i < numberOfBeeps; i++)
			Console.Beep(400 + (100 * numberOfBeeps), 100);
	}

}


// Mutation\ScreenCaptureForm.Designer.cs
// ------------------------------

namespace ScreenCapturing
{
	partial class ScreenCaptureForm
	{
		/// <summary>
		/// Required designer variable.
		/// </summary>
		private System.ComponentModel.IContainer components = null;

		/// <summary>
		/// Clean up any resources being used.
		/// </summary>
		/// <param name="disposing">true if managed resources should be disposed; otherwise, false.</param>
		protected override void Dispose(bool disposing)
		{
			if (disposing && (components != null))
			{
				components.Dispose();
			}
			base.Dispose(disposing);
		}

		#region Windows Form Designer generated code

		/// <summary>
		/// Required method for Designer support - do not modify
		/// the contents of this method with the code editor.
		/// </summary>
		private void InitializeComponent()
		{
			SuspendLayout();
			// 
			// ScreenCaptureForm
			// 
			AutoScaleDimensions = new SizeF(7F, 15F);
			AutoScaleMode = AutoScaleMode.Font;
			ClientSize = new Size(800, 450);
			Name = "ScreenCaptureForm";
			Text = "Screen Capture Form";
			TopMost = true;
			FormClosing += ScreenCaptureForm_FormClosing;
			ResumeLayout(false);
		}

		#endregion
	}
}


// Mutation\ScreenCaptureForm.cs
// ------------------------------

namespace ScreenCapturing
{
	public partial class ScreenCaptureForm : Form
	{
		private Bitmap screenshot;
		private Bitmap overlay; // New overlay for the crosshair
		private Rectangle selectedRegion;
		private Point firstPoint;

		public ScreenCaptureForm(Bitmap screenshot)
		{
			InitializeComponent();
			this.Bounds = Screen.PrimaryScreen.Bounds;
			this.FormBorderStyle = FormBorderStyle.None; // Hide title bar
			this.WindowState = FormWindowState.Maximized;
			this.DoubleBuffered = true; // Enable double buffering
			this.screenshot = screenshot; // Receive the screenshot
			this.Cursor = Cursors.Cross; // Change the cursor to a crosshair

			// Initialize the overlay with the same size as the screenshot
			overlay = new Bitmap(screenshot.Width, screenshot.Height);
			Invalidate(); // Invalidate to refresh the form display

			// Make sure this form is always the topmost form when it opens. This is particularly useful if the main application is hidden when the hotkey is pressed to capture the screen. 
			this.Activate();
		}

		protected override void OnMouseDown(MouseEventArgs e)
		{
			firstPoint = e.Location;
			base.OnMouseDown(e);
		}

		protected override void OnMouseMove(MouseEventArgs e)
		{
			// Clear the overlay
			using (Graphics gOverlay = Graphics.FromImage(overlay))
			{
				gOverlay.Clear(Color.Transparent);

				// Draw the crosshair on the overlay
				using (Pen crosshairPen = new Pen(Color.Green, 1))
				{
					gOverlay.DrawLine(crosshairPen, e.X, 0, e.X, Height);
					gOverlay.DrawLine(crosshairPen, 0, e.Y, Width, e.Y);
				}
			}

			if (e.Button == MouseButtons.Left)
			{
				selectedRegion = new Rectangle(Math.Min(firstPoint.X, e.X), Math.Min(firstPoint.Y, e.Y),
					Math.Abs(e.X - firstPoint.X), Math.Abs(e.Y - firstPoint.Y));
			}

			Invalidate(); // Forces the form to repaint
			base.OnMouseMove(e);
		}

		protected override void OnMouseUp(MouseEventArgs e)
		{
			if (e.Button == MouseButtons.Right)
			{
				this.Close(); // Right-click to cancel and close the form
				return;
			}

			if (selectedRegion.Width > 0 && selectedRegion.Height > 0)
			{
				using (Bitmap selectedImage = new Bitmap(selectedRegion.Width, selectedRegion.Height))
				{
					using (Graphics g = Graphics.FromImage(selectedImage))
					{
						g.DrawImage(screenshot, 0, 0, selectedRegion, GraphicsUnit.Pixel);
					}

					Clipboard.SetImage(selectedImage); // Copies the image to the clipboard
				}

				// Revert the cursor to the standard mouse pointer
				this.Cursor = Cursors.Default;
				this.Close(); // Explicitly close the form
			}
			base.OnMouseUp(e);
		}

		protected override void OnPaint(PaintEventArgs e)
		{
			if (screenshot != null) // Check to ensure screenshot is not null
			{
				e.Graphics.DrawImage(screenshot, 0, 0);
				e.Graphics.DrawImage(overlay, 0, 0); // Draw the overlay containing the crosshair

				// Draw the selected region
				using (Pen pen = new Pen(Color.Red, 2))
				{
					e.Graphics.DrawRectangle(pen, selectedRegion);
				}
			}
			base.OnPaint(e);
		}

		private void ScreenCaptureForm_FormClosing(object sender, FormClosingEventArgs e)
		{
			overlay?.Dispose();
			screenshot?.Dispose();
		}
	}
}



// Mutation\SettingsManager.cs
// ------------------------------

using CognitiveSupport;
using Newtonsoft.Json;
using Newtonsoft.Json.Converters;
using OpenAI.ObjectModels;
using System.Diagnostics;
using System.Text;

namespace Mutation;

internal class SettingsManager : ISettingsManager
{
	private static readonly JsonSerializerSettings _jsonSerializerSettings = new JsonSerializerSettings
	{
		Converters = new List<JsonConverter> { new StringEnumConverter() }
	};

	private string SettingsFilePath { get; set; }
	private string SettingsFileFullPath => Path.GetFullPath(SettingsFilePath);

	public SettingsManager(
		string settingsFilePath)
	{
		SettingsFilePath = settingsFilePath;
	}

	private void CreateSettingsFileOfNotExists(string fullPath)
	{
		if (!File.Exists(fullPath))
		{
			var settings = new Settings();
			EnsureSettings(settings);

			SaveSettingsToFile(settings);
			Process.Start("notepad.exe", SettingsFilePath);
		}
	}

	private bool EnsureSettings(Settings settings)
	{
		const string PlaceholderValue = "<placeholder>";
		const string PlaceholderUrl = "https://placeholder.com";

		bool somethingWasMissing = false;

		settings.UserInstructions = "Change the values of the settings below to your preferences, save the file, and restart Mutation.exe. DeploymentId in the LlmSettings should be set to your Azure model Deployment Name.";

		if (settings.AzureComputerVisionSettings is null)
		{
			settings.AzureComputerVisionSettings = new AzureComputerVisionSettings();
			somethingWasMissing = true;
		}
		var azureComputerVisionSettings = settings.AzureComputerVisionSettings;
		if (string.IsNullOrWhiteSpace(azureComputerVisionSettings.OcrHotKey))
		{
			azureComputerVisionSettings.OcrHotKey = "ALT+J";
			somethingWasMissing = true;
		}

		if (string.IsNullOrWhiteSpace(azureComputerVisionSettings.ScreenshotHotKey))
		{
			azureComputerVisionSettings.ScreenshotHotKey = "SHIFT+ALT+K";
			somethingWasMissing = true;
		}

		if (string.IsNullOrWhiteSpace(azureComputerVisionSettings.ScreenshotOcrHotKey))
		{
			azureComputerVisionSettings.ScreenshotOcrHotKey = "SHIFT+ALT+J";
			somethingWasMissing = true;
		}
		if (string.IsNullOrWhiteSpace(azureComputerVisionSettings.ApiKey))
		{
			azureComputerVisionSettings.ApiKey = PlaceholderValue;
			somethingWasMissing = true;
		}
		if (string.IsNullOrWhiteSpace(azureComputerVisionSettings.Endpoint))
		{
			azureComputerVisionSettings.Endpoint = PlaceholderUrl;
			somethingWasMissing = true;
		}


		//--------------------------------------
		if (settings.AudioSettings is null)
		{
			settings.AudioSettings = new AudioSettings();
			somethingWasMissing = true;
		}
		var audioSettings = settings.AudioSettings;
		if (string.IsNullOrWhiteSpace(audioSettings.MicrophoneToggleMuteHotKey))
		{
			audioSettings.MicrophoneToggleMuteHotKey = "ALT+Q";
			somethingWasMissing = true;
		}


		//----------------------------------
		if (settings.SpeetchToTextSettings is null)
		{
			settings.SpeetchToTextSettings = new SpeetchToTextSettings();
			somethingWasMissing = true;
		}
		var speechToTextSettings = settings.SpeetchToTextSettings;
		if (string.IsNullOrWhiteSpace(speechToTextSettings.SpeechToTextHotKey))
		{
			speechToTextSettings.SpeechToTextHotKey = "SHIFT+ALT+U";
			somethingWasMissing = true;
		}
		if (speechToTextSettings.Service == SpeechToTextServices.None)
		{
			speechToTextSettings.Service = SpeechToTextServices.OpenAiWhisper;
		}
		if (string.IsNullOrWhiteSpace(speechToTextSettings.SpeechToTextHotKey))
		{
			speechToTextSettings.SpeechToTextHotKey = "SHIFT+ALT+U";
			somethingWasMissing = true;
		}
		if (string.IsNullOrWhiteSpace(speechToTextSettings.ApiKey))
		{
			speechToTextSettings.ApiKey = PlaceholderValue;
			somethingWasMissing = true;
		}
		if (string.IsNullOrWhiteSpace(speechToTextSettings.TempDirectory))
		{
			speechToTextSettings.TempDirectory = @"C:\Temp\Mutation";
			somethingWasMissing = true;
		}

		if (string.IsNullOrWhiteSpace(speechToTextSettings.SpeechToTextPrompt))
		{
			speechToTextSettings.SpeechToTextPrompt = "Hello, let's use punctuation. Names: Kobus, Piro.";
			// This is optional, so we don't need to flag that something was missing.
		}


		//-------------------------------
		if (settings.LlmSettings is null)
		{
			settings.LlmSettings = new LlmSettings();
			somethingWasMissing = true;
		}
		var llmSettings = settings.LlmSettings;
		if (string.IsNullOrWhiteSpace(llmSettings.ApiKey))
		{
			llmSettings.ApiKey = PlaceholderValue;
			somethingWasMissing = true;
		}

		if (string.IsNullOrWhiteSpace(llmSettings.ResourceName))
		{
			llmSettings.ResourceName = "The-Azure-resource-name-for-your-OpenAI-service";
			somethingWasMissing = true;
		}

		if (string.IsNullOrWhiteSpace(llmSettings.FormatTranscriptPrompt))
		{
			//TODO: formatting is now done with normal code, so this should be deleted.

			llmSettings.FormatTranscriptPrompt = @"You are a helpful proofreader and editor. When you are asked to format a transcript, apply the following rules to improve the formatting of the text:
Replace the words 'new line' (case insensitive) with an actual new line character, and replace the words 'new paragraph' (case insensitive) with 2 new line characters, and replace the words 'new bullet' (case insensitive) with a newline character and a bullet character, eg. '- ', and end the preceding sentence with a full stop '.', and start the new sentence with a capital letter, and do not make any other changes.

Here is an example of a raw transcript and the reformatted text:

----- Transcript:
The radiology report - the written analysis by the radiologist interpreting your imaging study - is transmitted to the requesting physician or medical specialist new line the doctor or specialist will then relay the full analysis to you, along with recommendations and/or prescriptions. New paragraph Depending on the results, this might include new bullet scheduling further diagnostic tests new bullet initiating a new medication regimen new bullet recommending physical therapy new bullet or possibly even planning for a surgical intervention. New paragraph. Collaboration among various healthcare professionals ensures that the information gleaned from the radiology report is utilized to provide the most effective and individualized care tailored to your specific condition and needs. New line end of summary.


----- Reformatted Text:
The radiology report - the written analysis by the radiologist interpreting your imaging study - is transmitted to the requesting physician or medical specialist.
The doctor or specialist will then relay the full analysis to you, along with recommendations and/or prescriptions.

Depending on the results, this might include:
- scheduling further diagnostic tests,
- initiating a new medication regimen,
- recommending physical therapy,
- or possibly even planning for a surgical intervention.

Collaboration among various healthcare professionals ensures that the information gleaned from the radiology report is utilized to provide the most effective and individualized care tailored to your specific condition and needs.
End of summary.
";
			// No need to mark something as missing.
			//somethingWasMissing = true;
		}

		if (string.IsNullOrWhiteSpace(llmSettings.ReviewTranscriptPrompt))
		{
			llmSettings.ReviewTranscriptPrompt = @"You are an expert medical AI assistant; your task is to help doctors specialising in radiology.

When you are asked to review a radiological report, you should do the following:

1) Check for spelling and grammar mistakes. (Semicolons ; are to be followed with a small letter word, unless the word is a proper noun or acronym.)
2) Check for logical consistency through out the report, and specifically between the body, or findings section, and the conclusion or comment.
- Example 1: If the report body indicates a tumour was present, the conclusion/comment should not contradict that.
- Example 2: Normal heart in the body, or findings, of the report with cardiomegaly in the conclusion/ comment, is a logical contradiction.
- Example 3: Using left and right incorrectly/interchangeably.
- Example 4: Measurements in the body or findings section of the report and the comment/conclusion should be consistent.
3) Specifically look out for mistakes common to audio transcriptions. E.g.
- Similar sounding words (Hypointense vs hyperintense, hypo- vs hyperdense, etc)
4) You should provide your feedback without preamble, in bullet form, and only if an issue was actually detected; where each issue found is listed as a bullet point; each bullet should be in the form: - <Issue type>: <correction instruction>.
Example issue 1: 
- Clarification: Change RVD non-reactive to HIV non-reactive to avoid confusion.
Example issue 2: 
- Spelling: Change ""subcentimeter hypodencities"" to ""subcentimeter hypodensities.""
Example issue 3: 
- Contradiction: Remove ""Bone fractures evident in left tibia"" from the comment, as it contradicts ""Normal bones"" in the body of the report.
Example issue 4: 
- Grammar: Change ""Additional low-density para-aortic pelvic and, inguinal lymphadenopathy."" to ""Additional low-density para-aortic, pelvic, and inguinal lymphadenopathy.""; to remove the misplaced comma after ""and"" to properly format the list.

When you are asked to apply revision corrections, you should do the following:

1)  For each of the correction instructions provided, apply the specific correction in question to the original transcript exactly as per the instruction.
2) If you are unable to apply the correction for any reason, add a note explaining why at the bottom of the transcript under a heading Review Feedback.
3) Besides the specific correction instructions, dont make any other changes to the original transcript.
";
			// No need to mark something as missing.
			//somethingWasMissing = true;
		}


		if (llmSettings.ModelDeploymentIdMaps == null || !llmSettings.ModelDeploymentIdMaps.Any())
		{
			llmSettings.ModelDeploymentIdMaps = new List<LlmSettings.ModelDeploymentIdMap>
			{
				new LlmSettings.ModelDeploymentIdMap
				{
					ModelName = Models.Gpt_3_5_Turbo,
					DeploymentId = "gpt-35-turbo"
				},
				new LlmSettings.ModelDeploymentIdMap
				{
					ModelName = Models.Gpt_4,
					DeploymentId = "gpt-4"
				},
			};

			// no need to flag as we set defaults.
			//somethingWasMissing = true;
		}

		if (llmSettings.TranscriptFormatRules == null || !llmSettings.TranscriptFormatRules.Any())
		{
			llmSettings.TranscriptFormatRules = new List<LlmSettings.TranscriptFormatRule>
			{
				new LlmSettings.TranscriptFormatRule
				{
					Find= "new line",
					ReplaceWith= $"{Environment.NewLine}",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "newline",
					ReplaceWith= $"{Environment.NewLine}",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "next line",
					ReplaceWith= $"{Environment.NewLine}",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "new paragraph",
					ReplaceWith= $"{Environment.NewLine}{Environment.NewLine}",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "new paragraphs",
					ReplaceWith= $"{Environment.NewLine}{Environment.NewLine}",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "next paragraph",
					ReplaceWith= $"{Environment.NewLine}{Environment.NewLine}",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "new bullet",
					ReplaceWith= $"{Environment.NewLine}- ",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "next bullet",
					ReplaceWith= $"{Environment.NewLine}- ",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "new colon",
					ReplaceWith= $": ",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "semicolon",
					ReplaceWith= $"; ",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "full stop",
					ReplaceWith= $". ",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "comma",
					ReplaceWith= $", ",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "exclamation mark",
					ReplaceWith= $"! ",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "question mark",
					ReplaceWith= $"? ",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "elipsis",
					ReplaceWith= $"... ",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},
				new LlmSettings.TranscriptFormatRule
				{
					Find= "dot dot dot",
					ReplaceWith= $"... ",
					CaseSensitive = false,
					MatchType = LlmSettings.TranscriptFormatRule.MatchTypeEnum.Smart,
				},


			};

			// No need to flag something as missing as we set defaults.
			//somethingWasMissing = true;
		}

		//----------------------------------
		if (settings.TextToSpeechSettings is null)
		{
			settings.TextToSpeechSettings = new TextToSpeechSettings();
			somethingWasMissing = true;
		}
		var textToSpeechSettings = settings.TextToSpeechSettings;
		if (string.IsNullOrWhiteSpace(textToSpeechSettings.TextToSpeechHotKey))
		{
			textToSpeechSettings.TextToSpeechHotKey = "CTRL+SHIFT+Q";
			somethingWasMissing = true;
		}

		if (settings.HotKeyRouterSettings is null || !settings.HotKeyRouterSettings.Mappings.Any())
		{
			settings.HotKeyRouterSettings = new();
			// Add a sample hotkey router mapping.
			settings.HotKeyRouterSettings.Mappings.Add
			(
				new HotKeyRouterSettings.HotKeyRouterMap("CONTROL+SHIFT+ALT+8", "CONTROL+SHIFT+ALT+9")
			);
		}

		return somethingWasMissing;
	}

	public void UpgradeSettings()
	{
		string json = File.ReadAllText(SettingsFileFullPath);

		Settings settings = JsonConvert.DeserializeObject<Settings>(json, _jsonSerializerSettings);

		if (settings.LlmSettings?.TranscriptFormatRules?.Count is 4 or 14)
		{
			// Get rid of the old defaults.
			settings.LlmSettings.TranscriptFormatRules.Clear();
		}

		SaveSettingsToFile(settings);
	}

	public void SaveSettingsToFile(Settings settings)
	{
		string json = JsonConvert.SerializeObject(settings, Formatting.Indented, _jsonSerializerSettings);
		File.WriteAllText(SettingsFilePath, json, Encoding.UTF8);
	}

	public Settings LoadAndEnsureSettings()
	{
		CreateSettingsFileOfNotExists(SettingsFileFullPath);

		UpgradeSettings();

		string json = File.ReadAllText(SettingsFileFullPath);
		Settings settings = JsonConvert.DeserializeObject<Settings>(json, _jsonSerializerSettings);

		if (EnsureSettings(settings))
		{
			SaveSettingsToFile(settings);
		}

		return settings;
	}
}



// Mutation\OcrState.cs
// ------------------------------

using CognitiveSupport;

namespace Mutation
{
	internal class OcrState
	{
		internal bool BusyWithTextExtraction => OcrCancellationTokenSource != null;
		internal CancellationTokenSource? OcrCancellationTokenSource { get; set; }

		public OcrState()
		{
		}

		internal void StartTextExtraction()
		{
			this.OcrCancellationTokenSource = new();
		}

		internal void StopTextExtraction()
		{
			if (this.OcrCancellationTokenSource is not null)
				this.OcrCancellationTokenSource.Cancel();
			this.OcrCancellationTokenSource = null;
		}


	}
}



// Mutation\SpeechToTextState.cs
// ------------------------------

using CognitiveSupport;

namespace Mutation
{
	internal class SpeechToTextState
	{
		internal SemaphoreSlim AudioRecorderLock { get; } = new SemaphoreSlim(1, 1);

		private Func<AudioRecorder> GetAudioRecorder;
		internal bool RecordingAudio => GetAudioRecorder() != null;

		internal CancellationTokenSource? TranscriptionCancellationTokenSource { get; set; }
		internal bool TranscribingAudio => TranscriptionCancellationTokenSource != null;

		public SpeechToTextState(
			Func<AudioRecorder> getAudioRecorder)
		{
			GetAudioRecorder = getAudioRecorder ?? throw new ArgumentNullException(nameof(getAudioRecorder));
		}

		internal void StartTranscription()
		{
			this.TranscriptionCancellationTokenSource = new();
		}

		internal void StopTranscription()
		{
			if (this.TranscriptionCancellationTokenSource is not null)
				this.TranscriptionCancellationTokenSource.Cancel();
			this.TranscriptionCancellationTokenSource = null;
		}


	}
}



// Mutation\CaptureDeviceComboItem.cs
// ------------------------------

using AudioSwitcher.AudioApi.CoreAudio;

namespace Mutation
{
	internal class CaptureDeviceComboItem
	{
		public CoreAudioDevice CaptureDevice { get; set; }
		public string Display =>
			$"{CaptureDevice.FullName}";

		public override string ToString()
		{
			return this.Display;
		}
	}
}



// Mutation\MutationForm.Designer.cs
// ------------------------------

namespace Mutation
{
	partial class MutationForm
	{
		/// <summary>
		/// Required designer variable.
		/// </summary>
		private System.ComponentModel.IContainer components = null;

		/// <summary>
		/// Clean up any resources being used.
		/// </summary>
		/// <param name="disposing">true if managed resources should be disposed; otherwise, false.</param>
		protected override void Dispose(bool disposing)
		{
			if (disposing && (components != null))
			{
				components.Dispose();
			}
			base.Dispose(disposing);
		}

		#region Windows Form Designer generated code

		/// <summary>
		/// Required method for Designer support - do not modify
		/// the contents of this method with the code editor.
		/// </summary>
		private void InitializeComponent()
		{
			components = new System.ComponentModel.Container();
			lblActiveMic = new Label();
			lblToggleMic = new Label();
			txtActiveMicrophoneMuteState = new TextBox();
			txtAllMics = new TextBox();
			lblOcrHotKey = new Label();
			lblSpeechToText = new Label();
			txtSpeechToText = new TextBox();
			txtOcr = new TextBox();
			lblScreenshotOcrHotKey = new Label();
			lblScreenshotHotKey = new Label();
			txtSpeechToTextPrompt = new TextBox();
			lblSpeechToTextPrompt = new Label();
			toolTip = new ToolTip(components);
			btnSpeechToTextRecord = new Button();
			lblFormatTranscriptPrompt = new Label();
			txtFormatTranscriptPrompt = new TextBox();
			btnClearFormattedTranscript = new Button();
			txtFormatTranscriptResponse = new TextBox();
			lblFormatTranscriptResponse = new Label();
			splitContainerLlmProcessing = new SplitContainer();
			chkFormattedTranscriptAppend = new CheckBox();
			cmbInsertInto3rdPartyApplication = new ComboBox();
			lblReviewTemperature = new Label();
			cmbReviewTemperature = new ComboBox();
			btnApplySelectedReviewIssues = new Button();
			dgvReview = new DataGridView();
			lblReviewTranscriptPrompt = new Label();
			chkAutoReviewTranscript = new CheckBox();
			txtReviewTranscriptPrompt = new TextBox();
			btnReviewTranscript = new Button();
			lblTranscriptReview = new Label();
			txtTranscriptReviewResponse = new TextBox();
			radAutoPunctuation = new RadioButton();
			gbPunctuation = new GroupBox();
			radManualPunctuation = new RadioButton();
			label1 = new Label();
			lblSpeechToTextService = new Label();
			txtSpeechToTextService = new TextBox();
			cmbActiveMicrophone = new ComboBox();
			((System.ComponentModel.ISupportInitialize)splitContainerLlmProcessing).BeginInit();
			splitContainerLlmProcessing.Panel1.SuspendLayout();
			splitContainerLlmProcessing.Panel2.SuspendLayout();
			splitContainerLlmProcessing.SuspendLayout();
			((System.ComponentModel.ISupportInitialize)dgvReview).BeginInit();
			gbPunctuation.SuspendLayout();
			SuspendLayout();
			// 
			// lblActiveMic
			// 
			lblActiveMic.AutoSize = true;
			lblActiveMic.Location = new Point(160, 15);
			lblActiveMic.Margin = new Padding(4, 0, 4, 0);
			lblActiveMic.Name = "lblActiveMic";
			lblActiveMic.Size = new Size(63, 15);
			lblActiveMic.TabIndex = 0;
			lblActiveMic.Text = "Active Mic";
			// 
			// lblToggleMic
			// 
			lblToggleMic.AutoSize = true;
			lblToggleMic.Location = new Point(18, 47);
			lblToggleMic.Margin = new Padding(4, 0, 4, 0);
			lblToggleMic.Name = "lblToggleMic";
			lblToggleMic.Size = new Size(16, 15);
			lblToggleMic.TabIndex = 2;
			lblToggleMic.Text = "...";
			// 
			// txtActiveMicrophoneMuteState
			// 
			txtActiveMicrophoneMuteState.AccessibleName = "Active Microphone Mute State";
			txtActiveMicrophoneMuteState.Anchor = AnchorStyles.Top | AnchorStyles.Right;
			txtActiveMicrophoneMuteState.Location = new Point(551, 13);
			txtActiveMicrophoneMuteState.Margin = new Padding(4, 3, 4, 3);
			txtActiveMicrophoneMuteState.Name = "txtActiveMicrophoneMuteState";
			txtActiveMicrophoneMuteState.ReadOnly = true;
			txtActiveMicrophoneMuteState.Size = new Size(621, 23);
			txtActiveMicrophoneMuteState.TabIndex = 2;
			// 
			// txtAllMics
			// 
			txtAllMics.Anchor = AnchorStyles.Top | AnchorStyles.Left | AnchorStyles.Right;
			txtAllMics.Location = new Point(252, 42);
			txtAllMics.Margin = new Padding(4, 3, 4, 3);
			txtAllMics.Multiline = true;
			txtAllMics.Name = "txtAllMics";
			txtAllMics.ReadOnly = true;
			txtAllMics.ScrollBars = ScrollBars.Vertical;
			txtAllMics.Size = new Size(927, 66);
			txtAllMics.TabIndex = 3;
			// 
			// lblOcrHotKey
			// 
			lblOcrHotKey.AutoSize = true;
			lblOcrHotKey.Location = new Point(18, 134);
			lblOcrHotKey.Margin = new Padding(4, 0, 4, 0);
			lblOcrHotKey.Name = "lblOcrHotKey";
			lblOcrHotKey.Size = new Size(16, 15);
			lblOcrHotKey.TabIndex = 5;
			lblOcrHotKey.Text = "...";
			// 
			// lblSpeechToText
			// 
			lblSpeechToText.AutoSize = true;
			lblSpeechToText.Location = new Point(18, 271);
			lblSpeechToText.Margin = new Padding(4, 0, 4, 0);
			lblSpeechToText.Name = "lblSpeechToText";
			lblSpeechToText.Size = new Size(16, 15);
			lblSpeechToText.TabIndex = 10;
			lblSpeechToText.Text = "...";
			// 
			// txtSpeechToText
			// 
			txtSpeechToText.Anchor = AnchorStyles.Top | AnchorStyles.Left | AnchorStyles.Right;
			txtSpeechToText.Location = new Point(252, 271);
			txtSpeechToText.Margin = new Padding(4, 3, 4, 3);
			txtSpeechToText.Multiline = true;
			txtSpeechToText.Name = "txtSpeechToText";
			txtSpeechToText.ScrollBars = ScrollBars.Vertical;
			txtSpeechToText.Size = new Size(927, 93);
			txtSpeechToText.TabIndex = 12;
			txtSpeechToText.TextChanged += txtSpeechToText_TextChanged;
			// 
			// txtOcr
			// 
			txtOcr.Anchor = AnchorStyles.Top | AnchorStyles.Left | AnchorStyles.Right;
			txtOcr.Location = new Point(252, 114);
			txtOcr.Margin = new Padding(4, 3, 4, 3);
			txtOcr.Multiline = true;
			txtOcr.Name = "txtOcr";
			txtOcr.ReadOnly = true;
			txtOcr.ScrollBars = ScrollBars.Vertical;
			txtOcr.Size = new Size(927, 79);
			txtOcr.TabIndex = 7;
			// 
			// lblScreenshotOcrHotKey
			// 
			lblScreenshotOcrHotKey.AutoSize = true;
			lblScreenshotOcrHotKey.Location = new Point(18, 158);
			lblScreenshotOcrHotKey.Margin = new Padding(4, 0, 4, 0);
			lblScreenshotOcrHotKey.Name = "lblScreenshotOcrHotKey";
			lblScreenshotOcrHotKey.Size = new Size(16, 15);
			lblScreenshotOcrHotKey.TabIndex = 6;
			lblScreenshotOcrHotKey.Text = "...";
			// 
			// lblScreenshotHotKey
			// 
			lblScreenshotHotKey.AutoSize = true;
			lblScreenshotHotKey.Location = new Point(18, 114);
			lblScreenshotHotKey.Margin = new Padding(4, 0, 4, 0);
			lblScreenshotHotKey.Name = "lblScreenshotHotKey";
			lblScreenshotHotKey.Size = new Size(16, 15);
			lblScreenshotHotKey.TabIndex = 4;
			lblScreenshotHotKey.Text = "...";
			// 
			// txtSpeechToTextPrompt
			// 
			txtSpeechToTextPrompt.AcceptsReturn = true;
			txtSpeechToTextPrompt.AccessibleDescription = "The speech-to-text prompt for potentially improving accuracy.";
			txtSpeechToTextPrompt.Anchor = AnchorStyles.Top | AnchorStyles.Left | AnchorStyles.Right;
			txtSpeechToTextPrompt.Location = new Point(252, 199);
			txtSpeechToTextPrompt.Margin = new Padding(4, 3, 4, 3);
			txtSpeechToTextPrompt.Multiline = true;
			txtSpeechToTextPrompt.Name = "txtSpeechToTextPrompt";
			txtSpeechToTextPrompt.ScrollBars = ScrollBars.Vertical;
			txtSpeechToTextPrompt.Size = new Size(927, 66);
			txtSpeechToTextPrompt.TabIndex = 9;
			// 
			// lblSpeechToTextPrompt
			// 
			lblSpeechToTextPrompt.AutoSize = true;
			lblSpeechToTextPrompt.Location = new Point(18, 199);
			lblSpeechToTextPrompt.Margin = new Padding(4, 0, 4, 0);
			lblSpeechToTextPrompt.Name = "lblSpeechToTextPrompt";
			lblSpeechToTextPrompt.Size = new Size(128, 15);
			lblSpeechToTextPrompt.TabIndex = 8;
			lblSpeechToTextPrompt.Text = "Speech To Text Prompt";
			// 
			// toolTip
			// 
			toolTip.AutomaticDelay = 400;
			toolTip.AutoPopDelay = 30000;
			toolTip.InitialDelay = 400;
			toolTip.IsBalloon = true;
			toolTip.ReshowDelay = 80;
			toolTip.ToolTipTitle = "Whisper Speech To Text Prompt";
			// 
			// btnSpeechToTextRecord
			// 
			btnSpeechToTextRecord.Location = new Point(167, 299);
			btnSpeechToTextRecord.Name = "btnSpeechToTextRecord";
			btnSpeechToTextRecord.Size = new Size(69, 23);
			btnSpeechToTextRecord.TabIndex = 11;
			btnSpeechToTextRecord.Text = "&Record";
			btnSpeechToTextRecord.UseVisualStyleBackColor = true;
			btnSpeechToTextRecord.Click += btnSpeechToTextRecord_Click;
			// 
			// lblFormatTranscriptPrompt
			// 
			lblFormatTranscriptPrompt.AutoSize = true;
			lblFormatTranscriptPrompt.Location = new Point(7, 2);
			lblFormatTranscriptPrompt.Margin = new Padding(4, 0, 4, 0);
			lblFormatTranscriptPrompt.Name = "lblFormatTranscriptPrompt";
			lblFormatTranscriptPrompt.Size = new Size(143, 15);
			lblFormatTranscriptPrompt.TabIndex = 13;
			lblFormatTranscriptPrompt.Text = "Format Transcript prompt";
			lblFormatTranscriptPrompt.Click += lblFormatTranscriptPrompt_Click;
			// 
			// txtFormatTranscriptPrompt
			// 
			txtFormatTranscriptPrompt.AcceptsReturn = true;
			txtFormatTranscriptPrompt.AccessibleDescription = "The speech-to-text prompt for potentially improving accuracy.";
			txtFormatTranscriptPrompt.Anchor = AnchorStyles.Top | AnchorStyles.Left | AnchorStyles.Right;
			txtFormatTranscriptPrompt.Location = new Point(7, 20);
			txtFormatTranscriptPrompt.Margin = new Padding(4, 3, 4, 3);
			txtFormatTranscriptPrompt.Multiline = true;
			txtFormatTranscriptPrompt.Name = "txtFormatTranscriptPrompt";
			txtFormatTranscriptPrompt.ScrollBars = ScrollBars.Vertical;
			txtFormatTranscriptPrompt.Size = new Size(509, 64);
			txtFormatTranscriptPrompt.TabIndex = 14;
			txtFormatTranscriptPrompt.Visible = false;
			// 
			// btnClearFormattedTranscript
			// 
			btnClearFormattedTranscript.Anchor = AnchorStyles.Top | AnchorStyles.Right;
			btnClearFormattedTranscript.Location = new Point(130, 90);
			btnClearFormattedTranscript.Name = "btnClearFormattedTranscript";
			btnClearFormattedTranscript.Size = new Size(52, 23);
			btnClearFormattedTranscript.TabIndex = 16;
			btnClearFormattedTranscript.Text = "&Clear";
			btnClearFormattedTranscript.UseVisualStyleBackColor = true;
			btnClearFormattedTranscript.Click += btnClearFormattedTranscript_Click;
			// 
			// txtFormatTranscriptResponse
			// 
			txtFormatTranscriptResponse.Anchor = AnchorStyles.Top | AnchorStyles.Bottom | AnchorStyles.Left | AnchorStyles.Right;
			txtFormatTranscriptResponse.Location = new Point(7, 118);
			txtFormatTranscriptResponse.Margin = new Padding(4, 3, 4, 3);
			txtFormatTranscriptResponse.Multiline = true;
			txtFormatTranscriptResponse.Name = "txtFormatTranscriptResponse";
			txtFormatTranscriptResponse.ScrollBars = ScrollBars.Vertical;
			txtFormatTranscriptResponse.Size = new Size(509, 217);
			txtFormatTranscriptResponse.TabIndex = 18;
			// 
			// lblFormatTranscriptResponse
			// 
			lblFormatTranscriptResponse.AutoSize = true;
			lblFormatTranscriptResponse.Location = new Point(7, 94);
			lblFormatTranscriptResponse.Margin = new Padding(4, 0, 4, 0);
			lblFormatTranscriptResponse.Name = "lblFormatTranscriptResponse";
			lblFormatTranscriptResponse.Size = new Size(117, 15);
			lblFormatTranscriptResponse.TabIndex = 15;
			lblFormatTranscriptResponse.Text = "Formatted Transcript";
			// 
			// splitContainerLlmProcessing
			// 
			splitContainerLlmProcessing.Anchor = AnchorStyles.Top | AnchorStyles.Bottom | AnchorStyles.Left | AnchorStyles.Right;
			splitContainerLlmProcessing.Location = new Point(4, 369);
			splitContainerLlmProcessing.Name = "splitContainerLlmProcessing";
			// 
			// splitContainerLlmProcessing.Panel1
			// 
			splitContainerLlmProcessing.Panel1.Controls.Add(chkFormattedTranscriptAppend);
			splitContainerLlmProcessing.Panel1.Controls.Add(cmbInsertInto3rdPartyApplication);
			splitContainerLlmProcessing.Panel1.Controls.Add(lblFormatTranscriptPrompt);
			splitContainerLlmProcessing.Panel1.Controls.Add(txtFormatTranscriptPrompt);
			splitContainerLlmProcessing.Panel1.Controls.Add(btnClearFormattedTranscript);
			splitContainerLlmProcessing.Panel1.Controls.Add(lblFormatTranscriptResponse);
			splitContainerLlmProcessing.Panel1.Controls.Add(txtFormatTranscriptResponse);
			// 
			// splitContainerLlmProcessing.Panel2
			// 
			splitContainerLlmProcessing.Panel2.Controls.Add(lblReviewTemperature);
			splitContainerLlmProcessing.Panel2.Controls.Add(cmbReviewTemperature);
			splitContainerLlmProcessing.Panel2.Controls.Add(btnApplySelectedReviewIssues);
			splitContainerLlmProcessing.Panel2.Controls.Add(dgvReview);
			splitContainerLlmProcessing.Panel2.Controls.Add(lblReviewTranscriptPrompt);
			splitContainerLlmProcessing.Panel2.Controls.Add(chkAutoReviewTranscript);
			splitContainerLlmProcessing.Panel2.Controls.Add(txtReviewTranscriptPrompt);
			splitContainerLlmProcessing.Panel2.Controls.Add(btnReviewTranscript);
			splitContainerLlmProcessing.Panel2.Controls.Add(lblTranscriptReview);
			splitContainerLlmProcessing.Panel2.Controls.Add(txtTranscriptReviewResponse);
			splitContainerLlmProcessing.Size = new Size(1175, 342);
			splitContainerLlmProcessing.SplitterDistance = 527;
			splitContainerLlmProcessing.TabIndex = 18;
			// 
			// chkFormattedTranscriptAppend
			// 
			chkFormattedTranscriptAppend.AutoSize = true;
			chkFormattedTranscriptAppend.Checked = true;
			chkFormattedTranscriptAppend.CheckState = CheckState.Checked;
			chkFormattedTranscriptAppend.Location = new Point(189, 93);
			chkFormattedTranscriptAppend.Name = "chkFormattedTranscriptAppend";
			chkFormattedTranscriptAppend.Size = new Size(68, 19);
			chkFormattedTranscriptAppend.TabIndex = 17;
			chkFormattedTranscriptAppend.Text = "&Append";
			chkFormattedTranscriptAppend.UseVisualStyleBackColor = true;
			// 
			// cmbInsertInto3rdPartyApplication
			// 
			cmbInsertInto3rdPartyApplication.Anchor = AnchorStyles.Top | AnchorStyles.Right;
			cmbInsertInto3rdPartyApplication.FormattingEnabled = true;
			cmbInsertInto3rdPartyApplication.Location = new Point(262, 92);
			cmbInsertInto3rdPartyApplication.Name = "cmbInsertInto3rdPartyApplication";
			cmbInsertInto3rdPartyApplication.Size = new Size(254, 23);
			cmbInsertInto3rdPartyApplication.TabIndex = 18;
			// 
			// lblReviewTemperature
			// 
			lblReviewTemperature.AutoSize = true;
			lblReviewTemperature.Location = new Point(197, 95);
			lblReviewTemperature.Margin = new Padding(4, 0, 4, 0);
			lblReviewTemperature.Name = "lblReviewTemperature";
			lblReviewTemperature.Size = new Size(74, 15);
			lblReviewTemperature.TabIndex = 24;
			lblReviewTemperature.Text = "Temperature";
			// 
			// cmbReviewTemperature
			// 
			cmbReviewTemperature.Anchor = AnchorStyles.Top | AnchorStyles.Right;
			cmbReviewTemperature.FormattingEnabled = true;
			cmbReviewTemperature.Location = new Point(277, 92);
			cmbReviewTemperature.Name = "cmbReviewTemperature";
			cmbReviewTemperature.Size = new Size(43, 23);
			cmbReviewTemperature.TabIndex = 21;
			// 
			// btnApplySelectedReviewIssues
			// 
			btnApplySelectedReviewIssues.Anchor = AnchorStyles.Top | AnchorStyles.Right;
			btnApplySelectedReviewIssues.Location = new Point(481, 91);
			btnApplySelectedReviewIssues.Name = "btnApplySelectedReviewIssues";
			btnApplySelectedReviewIssues.Size = new Size(149, 23);
			btnApplySelectedReviewIssues.TabIndex = 22;
			btnApplySelectedReviewIssues.Text = "&Apply Selected";
			btnApplySelectedReviewIssues.UseVisualStyleBackColor = true;
			btnApplySelectedReviewIssues.Click += btnApplySelectedReviewIssues_Click;
			// 
			// dgvReview
			// 
			dgvReview.ColumnHeadersHeightSizeMode = DataGridViewColumnHeadersHeightSizeMode.AutoSize;
			dgvReview.Location = new Point(114, 106);
			dgvReview.Name = "dgvReview";
			dgvReview.RowTemplate.Height = 25;
			dgvReview.Size = new Size(240, 150);
			dgvReview.TabIndex = 20;
			dgvReview.RowsAdded += dgvReview_RowsAdded;
			dgvReview.RowsRemoved += dgvReview_RowsRemoved;
			// 
			// lblReviewTranscriptPrompt
			// 
			lblReviewTranscriptPrompt.AutoSize = true;
			lblReviewTranscriptPrompt.Location = new Point(4, 3);
			lblReviewTranscriptPrompt.Margin = new Padding(4, 0, 4, 0);
			lblReviewTranscriptPrompt.Name = "lblReviewTranscriptPrompt";
			lblReviewTranscriptPrompt.Size = new Size(142, 15);
			lblReviewTranscriptPrompt.TabIndex = 18;
			lblReviewTranscriptPrompt.Text = "Review Transcript prompt";
			lblReviewTranscriptPrompt.Click += lblReviewTranscriptPrompt_Click;
			// 
			// chkAutoReviewTranscript
			// 
			chkAutoReviewTranscript.Anchor = AnchorStyles.Top | AnchorStyles.Right;
			chkAutoReviewTranscript.Location = new Point(55, 91);
			chkAutoReviewTranscript.Name = "chkAutoReviewTranscript";
			chkAutoReviewTranscript.Size = new Size(153, 25);
			chkAutoReviewTranscript.TabIndex = 21;
			chkAutoReviewTranscript.Text = "A&uto review transcript";
			chkAutoReviewTranscript.UseVisualStyleBackColor = true;
			chkAutoReviewTranscript.Visible = false;
			// 
			// txtReviewTranscriptPrompt
			// 
			txtReviewTranscriptPrompt.AcceptsReturn = true;
			txtReviewTranscriptPrompt.AccessibleDescription = "The speech-to-text prompt for potentially improving accuracy.";
			txtReviewTranscriptPrompt.Anchor = AnchorStyles.Top | AnchorStyles.Left | AnchorStyles.Right;
			txtReviewTranscriptPrompt.Location = new Point(4, 21);
			txtReviewTranscriptPrompt.Margin = new Padding(4, 3, 4, 3);
			txtReviewTranscriptPrompt.Multiline = true;
			txtReviewTranscriptPrompt.Name = "txtReviewTranscriptPrompt";
			txtReviewTranscriptPrompt.ScrollBars = ScrollBars.Vertical;
			txtReviewTranscriptPrompt.Size = new Size(633, 64);
			txtReviewTranscriptPrompt.TabIndex = 19;
			// 
			// btnReviewTranscript
			// 
			btnReviewTranscript.Anchor = AnchorStyles.Top | AnchorStyles.Right;
			btnReviewTranscript.Location = new Point(326, 91);
			btnReviewTranscript.Name = "btnReviewTranscript";
			btnReviewTranscript.Size = new Size(149, 23);
			btnReviewTranscript.TabIndex = 21;
			btnReviewTranscript.Text = "Re&view Transcript";
			btnReviewTranscript.UseVisualStyleBackColor = true;
			btnReviewTranscript.Click += btnReviewTranscript_Click;
			// 
			// lblTranscriptReview
			// 
			lblTranscriptReview.AutoSize = true;
			lblTranscriptReview.Location = new Point(4, 95);
			lblTranscriptReview.Margin = new Padding(4, 0, 4, 0);
			lblTranscriptReview.Name = "lblTranscriptReview";
			lblTranscriptReview.Size = new Size(44, 15);
			lblTranscriptReview.TabIndex = 20;
			lblTranscriptReview.Text = "Review";
			lblTranscriptReview.Click += lblTranscriptReview_Click;
			// 
			// txtTranscriptReviewResponse
			// 
			txtTranscriptReviewResponse.Anchor = AnchorStyles.Top | AnchorStyles.Bottom | AnchorStyles.Left | AnchorStyles.Right;
			txtTranscriptReviewResponse.Location = new Point(4, 119);
			txtTranscriptReviewResponse.Margin = new Padding(4, 3, 4, 3);
			txtTranscriptReviewResponse.Multiline = true;
			txtTranscriptReviewResponse.Name = "txtTranscriptReviewResponse";
			txtTranscriptReviewResponse.ScrollBars = ScrollBars.Vertical;
			txtTranscriptReviewResponse.Size = new Size(633, 217);
			txtTranscriptReviewResponse.TabIndex = 20;
			// 
			// radAutoPunctuation
			// 
			radAutoPunctuation.AutoSize = true;
			radAutoPunctuation.Checked = true;
			radAutoPunctuation.Location = new Point(6, 19);
			radAutoPunctuation.Name = "radAutoPunctuation";
			radAutoPunctuation.Size = new Size(119, 19);
			radAutoPunctuation.TabIndex = 19;
			radAutoPunctuation.TabStop = true;
			radAutoPunctuation.Text = "Auto Punctuation";
			radAutoPunctuation.UseVisualStyleBackColor = true;
			// 
			// gbPunctuation
			// 
			gbPunctuation.Controls.Add(radManualPunctuation);
			gbPunctuation.Controls.Add(radAutoPunctuation);
			gbPunctuation.Location = new Point(4, 282);
			gbPunctuation.Name = "gbPunctuation";
			gbPunctuation.Size = new Size(152, 71);
			gbPunctuation.TabIndex = 20;
			gbPunctuation.TabStop = false;
			// 
			// radManualPunctuation
			// 
			radManualPunctuation.AutoSize = true;
			radManualPunctuation.Location = new Point(6, 44);
			radManualPunctuation.Name = "radManualPunctuation";
			radManualPunctuation.Size = new Size(133, 19);
			radManualPunctuation.TabIndex = 20;
			radManualPunctuation.Text = "Manual Punctuation";
			radManualPunctuation.UseVisualStyleBackColor = true;
			// 
			// label1
			// 
			label1.AutoSize = true;
			label1.Location = new Point(575, 410);
			label1.Margin = new Padding(4, 0, 4, 0);
			label1.Name = "label1";
			label1.Size = new Size(128, 15);
			label1.TabIndex = 21;
			label1.Text = "Speech To Text Prompt";
			// 
			// lblSpeechToTextService
			// 
			lblSpeechToTextService.AutoSize = true;
			lblSpeechToTextService.Location = new Point(18, 220);
			lblSpeechToTextService.Name = "lblSpeechToTextService";
			lblSpeechToTextService.Size = new Size(47, 15);
			lblSpeechToTextService.TabIndex = 22;
			lblSpeechToTextService.Text = "Service:";
			// 
			// txtSpeechToTextService
			// 
			txtSpeechToTextService.Location = new Point(71, 217);
			txtSpeechToTextService.Name = "txtSpeechToTextService";
			txtSpeechToTextService.ReadOnly = true;
			txtSpeechToTextService.Size = new Size(174, 23);
			txtSpeechToTextService.TabIndex = 23;
			// 
			// cmbActiveMicrophone
			// 
			cmbActiveMicrophone.AccessibleName = "Active Microphone";
			cmbActiveMicrophone.Anchor = AnchorStyles.Top | AnchorStyles.Left | AnchorStyles.Right;
			cmbActiveMicrophone.DropDownStyle = ComboBoxStyle.DropDownList;
			cmbActiveMicrophone.FormattingEnabled = true;
			cmbActiveMicrophone.Location = new Point(252, 12);
			cmbActiveMicrophone.Name = "cmbActiveMicrophone";
			cmbActiveMicrophone.Size = new Size(292, 23);
			cmbActiveMicrophone.TabIndex = 1;
			cmbActiveMicrophone.SelectedIndexChanged += cmbActiveMicrophone_SelectedIndexChanged;
			// 
			// MutationForm
			// 
			AutoScaleDimensions = new SizeF(7F, 15F);
			AutoScaleMode = AutoScaleMode.Font;
			ClientSize = new Size(1184, 711);
			Controls.Add(cmbActiveMicrophone);
			Controls.Add(txtSpeechToTextService);
			Controls.Add(lblSpeechToTextService);
			Controls.Add(label1);
			Controls.Add(gbPunctuation);
			Controls.Add(splitContainerLlmProcessing);
			Controls.Add(btnSpeechToTextRecord);
			Controls.Add(lblSpeechToTextPrompt);
			Controls.Add(txtSpeechToTextPrompt);
			Controls.Add(lblScreenshotHotKey);
			Controls.Add(lblScreenshotOcrHotKey);
			Controls.Add(txtOcr);
			Controls.Add(txtSpeechToText);
			Controls.Add(lblSpeechToText);
			Controls.Add(lblOcrHotKey);
			Controls.Add(txtAllMics);
			Controls.Add(txtActiveMicrophoneMuteState);
			Controls.Add(lblToggleMic);
			Controls.Add(lblActiveMic);
			Margin = new Padding(4, 3, 4, 3);
			Name = "MutationForm";
			StartPosition = FormStartPosition.CenterScreen;
			Text = "Mutation";
			FormClosing += MutationForm_FormClosing;
			Load += MutationForm_Load;
			splitContainerLlmProcessing.Panel1.ResumeLayout(false);
			splitContainerLlmProcessing.Panel1.PerformLayout();
			splitContainerLlmProcessing.Panel2.ResumeLayout(false);
			splitContainerLlmProcessing.Panel2.PerformLayout();
			((System.ComponentModel.ISupportInitialize)splitContainerLlmProcessing).EndInit();
			splitContainerLlmProcessing.ResumeLayout(false);
			((System.ComponentModel.ISupportInitialize)dgvReview).EndInit();
			gbPunctuation.ResumeLayout(false);
			gbPunctuation.PerformLayout();
			ResumeLayout(false);
			PerformLayout();
		}

		#endregion

		private Label lblActiveMic;
		private Label lblToggleMic;
		private TextBox txtActiveMicrophoneMuteState;
		private TextBox txtAllMics;
		private Label lblOcrHotKey;
		private Label lblSpeechToText;
		private TextBox txtSpeechToText;
		private TextBox txtOcr;
		private Label lblScreenshotOcrHotKey;
		private Label lblScreenshotHotKey;
		private TextBox txtSpeechToTextPrompt;
		private Label lblSpeechToTextPrompt;
		private ToolTip toolTip;
		private Button btnSpeechToTextRecord;
		private Label lblFormatTranscriptPrompt;
		private TextBox txtFormatTranscriptPrompt;
		private Button btnClearFormattedTranscript;
		private TextBox txtFormatTranscriptResponse;
		private Label lblFormatTranscriptResponse;
		private SplitContainer splitContainerLlmProcessing;
		private Label lblReviewTranscriptPrompt;
		private CheckBox chkAutoReviewTranscript;
		private TextBox txtReviewTranscriptPrompt;
		private Button btnReviewTranscript;
		private Label lblTranscriptReview;
		private TextBox txtTranscriptReviewResponse;
		private DataGridView dgvReview;
		private Button btnApplySelectedReviewIssues;
		private RadioButton radAutoPunctuation;
		private GroupBox gbPunctuation;
		private RadioButton radManualPunctuation;
		private ComboBox cmbInsertInto3rdPartyApplication;
		private CheckBox chkFormattedTranscriptAppend;
		private Label lblReviewTemperature;
		private ComboBox cmbReviewTemperature;
		private Label label1;
		private Label lblSpeechToTextService;
		private TextBox txtSpeechToTextService;
		private ComboBox cmbActiveMicrophone;
	}
}




// Mutation\MutationForm.cs
// ------------------------------

using AudioSwitcher.AudioApi;
using AudioSwitcher.AudioApi.CoreAudio;
using CognitiveSupport;
using CognitiveSupport.Extensions;
using NAudio.Wave;
using OpenAI.ObjectModels;
using OpenAI.ObjectModels.RequestModels;
using ScreenCapturing;
using StringExtensionLibrary;
using System.ComponentModel;
using System.Drawing.Imaging;

namespace Mutation
{
	public partial class MutationForm : Form
	{
		private ScreenCaptureForm _activeScreenCaptureForm = null;

		private Settings _settings { get; set; }
		private ISettingsManager _settingsManager { get; set; }

		private Hotkey _hkToggleMicMute;
		private bool _isMuted = false;
		private CoreAudioController _coreAudioController;
		private IEnumerable<CoreAudioDevice> _captureDevices;
		private CoreAudioDevice _microphone { get; set; }
		private int _microphoneDeviceIndex = -1;

		private Hotkey _hkSpeechToText { get; set; }
		private ISpeechToTextService _speechToTextService { get; set; }
		private AudioRecorder _audioRecorder { get; set; }
		private SpeechToTextState _speechToTextState { get; init; }

		private Hotkey _hkScreenshot;
		private Hotkey _hkScreenshotOcr;
		private Hotkey _hkOcr;
		private IOcrService _ocrService { get; set; }
		private OcrState _ocrState { get; init; } = new();

		private ILlmService _llmService { get; set; }

		private Hotkey _hkTextToSpeech { get; set; }
		private ITextToSpeechService _textToSpeechService;

		private List<Hotkey> HotKeyRouterFromEntries { get; set; } = new();

		public MutationForm(
			ISettingsManager settingsManager,
			Settings settings,
			CoreAudioController coreAudioController,
			IOcrService ocrService,
			ISpeechToTextService speechToTextService,
			ITextToSpeechService textToSpeechService,
			ILlmService llmService)
		{
			this._settingsManager = settingsManager ?? throw new ArgumentNullException(nameof(settingsManager));
			this._settings = settings ?? throw new ArgumentNullException(nameof(settings));
			this._coreAudioController = coreAudioController ?? throw new ArgumentNullException(nameof(coreAudioController));
			this._ocrService = ocrService ?? throw new ArgumentNullException(nameof(ocrService));
			this._speechToTextService = speechToTextService ?? throw new ArgumentNullException(nameof(speechToTextService));
			this._textToSpeechService = textToSpeechService ?? throw new ArgumentNullException(nameof(textToSpeechService));
			this._llmService = llmService ?? throw new ArgumentNullException(nameof(llmService));
			this._speechToTextState = new SpeechToTextState(() => _audioRecorder);


			InitializeComponent();
			InitializeAudioControls();

			txtSpeechToTextPrompt.Text = _settings.SpeetchToTextSettings.SpeechToTextPrompt;

			HookupTooltips();

			HookupHotkeys();

			txtFormatTranscriptPrompt.Text = this._settings.LlmSettings.FormatTranscriptPrompt;
			txtReviewTranscriptPrompt.Text = this._settings.LlmSettings.ReviewTranscriptPrompt;

			InitializeLlmReviewListView();

			cmbInsertInto3rdPartyApplication.DropDownStyle = ComboBoxStyle.DropDownList;
			foreach (DictationInsertOption option in Enum.GetValues(typeof(DictationInsertOption)))
			{
				string description = GetEnumDescription(option);
				cmbInsertInto3rdPartyApplication.Items.Add(new { Text = description, Value = option });
			}
			cmbInsertInto3rdPartyApplication.DisplayMember = "Text";
			cmbInsertInto3rdPartyApplication.ValueMember = "Value";
			cmbInsertInto3rdPartyApplication.SelectedIndex = 2;


			cmbReviewTemperature.DropDownStyle = ComboBoxStyle.DropDownList;
			for (decimal d = 0.0m; d < 1.9m; d = d + 0.1m)
			{
				cmbReviewTemperature.Items.Add(new { Text = $"{d}", Value = d });
			}
			cmbReviewTemperature.DisplayMember = "Text";
			cmbReviewTemperature.ValueMember = "Value";
			cmbReviewTemperature.SelectedIndex = 4;


			//BookMark??999

		}

		public static string GetEnumDescription(Enum value)
		{
			var fieldInfo = value.GetType().GetField(value.ToString());
			var attributes = (DescriptionAttribute[])fieldInfo.GetCustomAttributes(typeof(DescriptionAttribute), false);

			if (attributes != null && attributes.Length > 0)
			{
				return attributes[0].Description;
			}
			else
			{
				return value.ToString();
			}
		}



		private void InitializeLlmReviewListView()
		{
			txtTranscriptReviewResponse.Visible = false;

			dgvReview.Location = txtTranscriptReviewResponse.Location;
			dgvReview.Height = txtTranscriptReviewResponse.Height;
			dgvReview.Width = txtTranscriptReviewResponse.Width;
			dgvReview.Anchor = AnchorStyles.Top | AnchorStyles.Left | AnchorStyles.Right | AnchorStyles.Bottom;
			dgvReview.AutoSizeRowsMode = DataGridViewAutoSizeRowsMode.AllCells;
			dgvReview.AutoGenerateColumns = false;
			dgvReview.RowHeadersVisible = false;
			dgvReview.MultiSelect = false;
			dgvReview.SelectionMode = DataGridViewSelectionMode.FullRowSelect;

			DataGridViewCheckBoxColumn checkBoxColumn = new DataGridViewCheckBoxColumn();
			checkBoxColumn.HeaderText = "Select";
			checkBoxColumn.AutoSizeMode = DataGridViewAutoSizeColumnMode.ColumnHeader;
			dgvReview.Columns.Add(checkBoxColumn);

			DataGridViewTextBoxColumn textColumn = new DataGridViewTextBoxColumn();
			textColumn.HeaderText = "Issue";
			textColumn.AutoSizeMode = DataGridViewAutoSizeColumnMode.Fill;
			textColumn.DefaultCellStyle.WrapMode = DataGridViewTriState.True;
			dgvReview.Columns.Add(textColumn);

			// Add sample data during dev time
			//dgvReview.Rows.Add(new object[] { false, "Long text item 1" });  // Adding an unchecked row
			//dgvReview.Rows.Add(new object[] { false, "Long text item 2...............................bla bla" });
			//dgvReview.Rows.Add(new object[] { false, "By setting the Anchor property to AnchorStyles.Top | AnchorStyles.Left | AnchorStyles.Right | AnchorStyles.Bottom, the DataGridView will be anchored to all four sides of its parent container. This means that it will resize itself appropriately when the parent container is resized, maintaining the specified distance to each edge." });
		}

		private void HookupTooltips()
		{
			string speechToTextPromptToolTipMsg = @"
You can use a prompt to improve the quality of the transcripts generated by the Whisper API. The model will try to match the style of the prompt, so it will be more likely to use capitalization and punctuation if the prompt does too. This only provides limited control over the generated audio. Here are some examples of how prompting can help in different scenarios:

Prompts can be very helpful for correcting specific words or acronyms that the model often misrecognizes in the audio. For example, the following prompt improves the transcription of the words DALLE and GPT-3, which were previously written as ""DALI"" and ""GDP 3"": The prompt is:
 OpenAI makes technology like DALLE, GPT-3, and ChatGPT with the hope of one day building an AGI system that benefits all of humanity""

Sometimes the model might skip punctuation in the transcript. You can avoid this by using a simple prompt that includes punctuation, such as: ""Hello, welcome to my lecture.""

The model may also leave out common filler words in the audio. If you want to keep the filler words in your transcript, you can use a prompt that contains them: ""Umm, let me think like, hmm... Okay, here's what I'm, like, thinking.""
";

			toolTip.SetToolTip(txtSpeechToTextPrompt, speechToTextPromptToolTipMsg);
			toolTip.SetToolTip(lblSpeechToTextPrompt, speechToTextPromptToolTipMsg);

			var voiceCommands = this._settings.LlmSettings.TranscriptFormatRules
				.Select(x => new
				{
					x.Find,
					ReplaceWith = x.ReplaceWith
							.Replace(Environment.NewLine, @"<new line>")
							.Replace(@"\t", @"<tab>"),
					x.MatchType,
					x.CaseSensitive
				})
				.Select(x => new
				{
					Rule = x,
					Spacing = string.Concat(Enumerable.Repeat(
						" ",
						Math.Abs(75 - $"{x.Find} = {x.ReplaceWith}".Length)))
				})
				.Select(x => $"{x.Rule.Find} = {x.Rule.ReplaceWith}{x.Spacing}(Match: {x.Rule.MatchType}, Case Sensitive: {x.Rule.CaseSensitive})")
				.ToArray();
			string formattingCommandsPromptToolTipMsg = $"You can use the following voice commands while dictating: {Environment.NewLine}{Environment.NewLine}{string.Join(Environment.NewLine, voiceCommands)}";
			toolTip.SetToolTip(lblSpeechToText, formattingCommandsPromptToolTipMsg);
			toolTip.SetToolTip(lblFormatTranscriptResponse, formattingCommandsPromptToolTipMsg);
		}

		private void RestoreWindowLocationAndSizeFromSettings()
		{
			if (_settings is null)
				return;

			if (_settings.MainWindowUiSettings.WindowSize != Size.Empty)
			{
				// Make sure the window size stays within the screen bounds
				this.Size = new Size(Math.Min(_settings.MainWindowUiSettings.WindowSize.Width, Screen.PrimaryScreen.Bounds.Width),
											Math.Min(_settings.MainWindowUiSettings.WindowSize.Height, Screen.PrimaryScreen.Bounds.Height));
			}

			if (this.Size.Width < 150 || this.Size.Height < 150)
			{
				this.Size = new Size(Math.Max(this.Size.Width, 150), Math.Max(this.Size.Height, 150));
			}

			if (_settings.MainWindowUiSettings.WindowLocation != Point.Empty)
			{
				// Make sure the window location stays within the screen bounds
				this.Location = new Point(Math.Max(Math.Min(_settings.MainWindowUiSettings.WindowLocation.X, Screen.PrimaryScreen.Bounds.Width - this.Size.Width), 0),
												  Math.Max(Math.Min(_settings.MainWindowUiSettings.WindowLocation.Y, Screen.PrimaryScreen.Bounds.Height - this.Size.Height), 0));

			}
		}

		internal void InitializeAudioControls()
		{
			txtActiveMicrophoneMuteState.Text = "(Initializing...)";

			Application.DoEvents();

			_captureDevices = _coreAudioController.GetDevices(DeviceType.Capture, DeviceState.Active);
			PopulateActiveMicrophoneCombo();
			SetActiveMicrophoneFromSettings();
			SetActiveMicrophoneToDefaultCaptureDeviceIfNotSet();
		}

		private void SetActiveMicrophoneToDefaultCaptureDeviceIfNotSet()
		{
			if (_microphone is null)
			{
				var defaultMicDevice = _captureDevices
					.FirstOrDefault(x => x.IsDefaultDevice);
				if (defaultMicDevice is not null)
				{
					this._microphone = defaultMicDevice;
					SelectCaptureDeviceForNAudioBasedRecording();
					SelectActiveCaptureDeviceInActiveMicrophoneCombo();

					FeedbackMicrophoneStateToUser();
				}
				else
				{
					txtActiveMicrophoneMuteState.Text = "(Unable to find device)";
					BeepFail();
				}
			}
		}

		private void SetActiveMicrophoneFromSettings()
		{
			foreach (CaptureDeviceComboItem item in cmbActiveMicrophone.Items)
			{
				if (item.CaptureDevice.FullName == _settings.AudioSettings.ActiveCaptureDeviceFullName)
				{
					cmbActiveMicrophone.SelectedItem = item;
					break;
				}
			}
		}

		private void PopulateActiveMicrophoneCombo()
		{
			cmbActiveMicrophone.Items.Clear();
			_captureDevices
				.ToList()
				.ForEach(m => cmbActiveMicrophone.Items.Add(new CaptureDeviceComboItem
				{
					CaptureDevice = m,
				}));
		}

		private void SelectActiveCaptureDeviceInActiveMicrophoneCombo()
		{
			foreach (CaptureDeviceComboItem item in cmbActiveMicrophone.Items)
			{
				if (item.CaptureDevice.FullName == _microphone.FullName)
				{
					cmbActiveMicrophone.SelectedItem = item;
					break;
				}
			}
		}

		private void SelectCaptureDeviceForNAudioBasedRecording()
		{
			// The AudioSwitcher library, CoreAudioDevice.Name returns a value like
			// "Krisp Michrophone". This is the name of the device as under Windows recording devices.
			// While the NAudio library(used for recording to file) property, WaveInEvent.GetCapabilities(i).ProductName, returns a value like
			// "Krisp Michrophone (Krisp Audio)". This has the device name, but also contains a suffix.
			// So, we do a starts with match to find the mic we are looking for using the default device name followed by a space and a (

			string startsWithNameToMatch = $"{this._microphone.Name} (";
			int deviceCount = WaveIn.DeviceCount;
			bool micMatchFound = false;
			for (int i = 0; i < deviceCount; i++)
			{
				if (WaveInEvent.GetCapabilities(i).ProductName.StartsWith(startsWithNameToMatch))
				{
					micMatchFound = true;
					_microphoneDeviceIndex = i;

					// Debugging message
					//MessageBox.Show(
					//	defaultMicDevice.Name
					//	+ Environment.NewLine
					//	+ WaveInEvent.GetCapabilities(i).ProductName
					//	+ Environment.NewLine
					//	+ "Device Index: " + _microphoneDeviceIndex);

					break;
				}
			}
			if (!micMatchFound)
				MessageBox.Show($"No michrophone match found for {this._microphone.Name}");
		}

		public void ToggleMicrophoneMute()
		{
			lock (this)
			{
				_isMuted = !_isMuted;
				foreach (var mic in _captureDevices)
					mic.Mute(_isMuted);

				FeedbackMicrophoneStateToUser();
			}
		}

		private void FeedbackMicrophoneStateToUser()
		{
			lock (this)
			{
				if (_microphone.IsMuted)
				{
					this.Text = "Mutation - Muted Microphone";
					this.BackColor = Color.LightGray;
					BeepMuted();
				}
				else // unmuted
				{
					this.Text = "Mutation - Unmuted Microphone";
					this.BackColor = Color.WhiteSmoke;
					BeepUnmuted();
				}

				txtActiveMicrophoneMuteState.Text = this._microphone.IsMuted ? "Muted" : "Unmuted";

				int i = 1;
				txtAllMics.Text = string.Join(Environment.NewLine, _captureDevices.Select(m => $"{i++}) {m.FullName}{(m.IsMuted ? "       - muted" : "")}").ToArray());
			}
		}

		private void HookupHotkeys()
		{
			HookupHotKeyToggleMichrophoneMuteHotkey();

			HookupHotKeyScreenshot();
			HookupHotKeyScreenshotOcr();
			HookupHotKeyOcr();

			HookupHotKeySpeechToText();
			HookupHotKeyTextToSpeech();

			HookupHotKeyRouter();
		}

		private void HookupHotKeyScreenshot()
		{
			_hkScreenshot = MapHotKey(_settings.AzureComputerVisionSettings.ScreenshotHotKey);
			_hkScreenshot.Pressed += delegate { TakeScreenshotToClipboard(); };
			TryRegisterHotkey(_hkScreenshot);

			lblScreenshotHotKey.Text = $"Screenshot: {_hkScreenshot}";
		}

		private void TakeScreenshotToClipboard()
		{
			if (_activeScreenCaptureForm is not null)
			{
				// If there is already an active capture form open, just make sure it is topmost and short-circuit.
				_activeScreenCaptureForm?.Activate();
				return;
			}

			using (Bitmap screenshot = new Bitmap(Screen.PrimaryScreen.Bounds.Width, Screen.PrimaryScreen.Bounds.Height))
			using (Graphics g = Graphics.FromImage(screenshot))
			{
				g.CopyFromScreen(0, 0, 0, 0, Screen.PrimaryScreen.Bounds.Size);
				using (ScreenCaptureForm screenCaptureForm = new ScreenCaptureForm(new Bitmap(screenshot)))
				{
					_activeScreenCaptureForm = screenCaptureForm;

					screenCaptureForm.TopMost = true;
					screenCaptureForm.ShowDialog();

					_activeScreenCaptureForm = null;
				}
			}
		}

		private void HookupHotKeyScreenshotOcr()
		{
			_hkScreenshotOcr = MapHotKey(_settings.AzureComputerVisionSettings.ScreenshotOcrHotKey);
			_hkScreenshotOcr.Pressed += delegate { TakeScreenshotAndExtractText(); };
			TryRegisterHotkey(_hkScreenshotOcr);

			lblScreenshotOcrHotKey.Text = $"Screenshot OCR: {_hkScreenshotOcr}";
		}

		private async void TakeScreenshotAndExtractText()
		{
			if (_activeScreenCaptureForm is not null)
			{
				// If there is already an active capture form open, just make sure it is topmost and short-circuit.
				_activeScreenCaptureForm?.Activate();
				return;
			}

			using (Bitmap screenshot = new Bitmap(Screen.PrimaryScreen.Bounds.Width, Screen.PrimaryScreen.Bounds.Height))
			using (Graphics g = Graphics.FromImage(screenshot))
			{
				g.CopyFromScreen(0, 0, 0, 0, Screen.PrimaryScreen.Bounds.Size);
				using (ScreenCaptureForm screenCaptureForm = new ScreenCaptureForm(new Bitmap(screenshot)))
				{
					_activeScreenCaptureForm = screenCaptureForm;

					screenCaptureForm.TopMost = true;
					screenCaptureForm.ShowDialog();

					_activeScreenCaptureForm = null;

					await ExtractTextViaOcrFromClipboardImage();
				}
			}
		}

		private void HookupHotKeyOcr()
		{
			_hkOcr = MapHotKey(_settings.AzureComputerVisionSettings.OcrHotKey);
			_hkOcr.Pressed += delegate
			{
				ExtractTextViaOcrFromClipboardImage();
			};
			TryRegisterHotkey(_hkOcr);

			lblOcrHotKey.Text = $"OCR Clipboard: {_hkOcr}";
		}

		private async Task ExtractTextViaOcrFromClipboardImage()
		{
			if (_ocrState.BusyWithTextExtraction)
			{
				_ocrState.StopTextExtraction();
				return;
			}

			var image = TryGetClipboardImage();
			if (image is null)
			{
				BeepFail();

				this.Activate();
				MessageBox.Show("No image found on the clipboard.", "Error", MessageBoxButtons.OK, MessageBoxIcon.Error);
			}

			try
			{
				_ocrState.StartTextExtraction();
				await ExtractTextViaOcr(TryGetClipboardImage());
			}
			finally
			{
				_ocrState.StopTextExtraction();
			}
		}

		private async Task ExtractTextViaOcr(
			Image image)
		{
			if (image is null)
			{
				txtOcr.Text = "No image provided to perform OCR on.";
				return;
			}

			try
			{
				BeepStart();

				txtOcr.Text = "Running OCR on image";

				using MemoryStream imageStream = new MemoryStream();
				image.Save(imageStream, ImageFormat.Jpeg);
				imageStream.Seek(0, SeekOrigin.Begin);
				string text = await this._ocrService.ExtractText(imageStream, _ocrState.OcrCancellationTokenSource.Token).ConfigureAwait(true);

				SetTextToClipboard(text);
				txtOcr.Text = $"Converted text is on clipboard:{Environment.NewLine}{text}";

				BeepSuccess();
			}
			catch (TaskCanceledException ex) when (ex.CancellationToken.IsCancellationRequested)
			{
				// This was an intentional cancellation by the user, so only beep the failure, but don't show an error message. 
				BeepFail();

				txtOcr.Text = "OCR cancelled by user.";
				SetTextToClipboard(txtOcr.Text);
			}
			catch (Exception ex)
			{
				string msg = $"Failed to extract text via OCR: {ex.Message}{Environment.NewLine}{ex.GetType().FullName}{Environment.NewLine}{ex.StackTrace}";
				txtOcr.Text = msg;

				BeepFail();
				SetTextToClipboard(msg);
			}
		}

		public Image TryGetClipboardImage()
		{
			int attempts = 5;

			while (attempts > 0)
			{
				if (Clipboard.ContainsImage())
				{
					return Clipboard.GetImage();
				}

				attempts--;
				Thread.Sleep(100);
			}

			return null;
		}

		// https://docs.microsoft.com/en-us/dotnet/desktop/winforms/advanced/how-to-retrieve-data-from-the-clipboard?view=netframeworkdesktop-4.8
		public void SetTextToClipboard(
			string text)
		{
			if (!string.IsNullOrWhiteSpace(text))
				Clipboard.SetText(text, TextDataFormat.UnicodeText);
		}

		private void HookupHotKeyToggleMichrophoneMuteHotkey()
		{
			_hkToggleMicMute = MapHotKey(_settings.AudioSettings.MicrophoneToggleMuteHotKey);
			_hkToggleMicMute.Pressed += delegate { ToggleMicrophoneMute(); };
			TryRegisterHotkey(_hkToggleMicMute);

			lblToggleMic.Text = $"Toggle Michrophone Mute: {_hkToggleMicMute}";
		}

		private void HookupHotKeySpeechToText()
		{
			_hkSpeechToText = MapHotKey(_settings.SpeetchToTextSettings.SpeechToTextHotKey);
			_hkSpeechToText.Pressed += delegate { SpeechToText(); };
			TryRegisterHotkey(_hkSpeechToText);

			lblSpeechToText.Text = $"Speach to Text: {_hkSpeechToText}";
		}

		private void HookupHotKeyTextToSpeech()
		{
			_hkTextToSpeech = MapHotKey(_settings.TextToSpeechSettings.TextToSpeechHotKey);
			_hkTextToSpeech.Pressed += delegate { TextToSpeech(); };
			TryRegisterHotkey(_hkTextToSpeech);

			//lblTextToSpeech.Text = $"Text to Speech: {_hkTextToSpeech}";
		}

		private void HookupHotKeyRouter()
		{
			foreach (var mapping in _settings.HotKeyRouterSettings.Mappings)
			{
				Hotkey fromHotKey = MapHotKey(mapping.FromHotKey);
				fromHotKey.Pressed += delegate { SendKeysAfterDelay(mapping.ToHotKey, 25); };
				if (TryRegisterHotkey(fromHotKey))
					this.HotKeyRouterFromEntries.Add(fromHotKey);
			}
		}

		private static void SendKeysAfterDelay(
			string hotkey,
			int delayMs)
		{
			System.Threading.Tasks.Task.Run(async () =>
			{
				await System.Threading.Tasks.Task.Delay(delayMs);
				System.Windows.Forms.SendKeys.SendWait(hotkey);
			});
		}

		private void TextToSpeech()
		{
			string text = Clipboard.GetText();
			_textToSpeechService.SpeakText(text);
		}

		private async Task SpeechToText()
		{
			try
			{
				if (this._speechToTextState.TranscribingAudio)
				{
					this._speechToTextState.StopTranscription();
					return;
				}

				string sessionsDirectory = Path.Combine(_settings.SpeetchToTextSettings.TempDirectory, Constants.SessionsDirectoryName);
				if (!Directory.Exists(sessionsDirectory))
					Directory.CreateDirectory(sessionsDirectory);

				string audioFilePath = Path.Combine(sessionsDirectory, "mutation_recording.mp3");

				await this._speechToTextState.AudioRecorderLock.WaitAsync().ConfigureAwait(true);
				{
					if (!this._speechToTextState.RecordingAudio)
					{
						txtSpeechToText.ReadOnly = true;
						txtSpeechToText.Text = "Recording microphone...";

						_audioRecorder = new AudioRecorder();
						_audioRecorder.StartRecording(_microphoneDeviceIndex, audioFilePath);
						btnSpeechToTextRecord.Text = "Stop &Recording";

						BeepStart();
					}
					else // Busy recording, so we want to stop it.
					{
						_audioRecorder.StopRecording();
						_audioRecorder.Dispose();
						_audioRecorder = null;

						BeepStart();

						txtSpeechToText.ReadOnly = true;
						txtSpeechToText.Text = "Converting speech to text...";

						btnSpeechToTextRecord.Text = "Processing";
						btnSpeechToTextRecord.Enabled = false;

						string text = "";
						_speechToTextState.StartTranscription();
						try
						{
							text = await this._speechToTextService.ConvertAudioToText(txtSpeechToTextPrompt.Text, audioFilePath, this._speechToTextState.TranscriptionCancellationTokenSource.Token).ConfigureAwait(true);
						}
						finally
						{
							_speechToTextState.StopTranscription();

							txtSpeechToText.ReadOnly = false;
							txtSpeechToText.Text = $"{text}";

							btnSpeechToTextRecord.Text = "&Record";
							btnSpeechToTextRecord.Enabled = true;
						}
					}
				}

			}
			catch (TaskCanceledException ex) when (ex.CancellationToken.IsCancellationRequested)
			{
				// This was an intentional cancellation by the user, so only beep the failure, but don't show an error message. 
				BeepFail();

				txtSpeechToText.Text = "Transcription cancelled by user.";
				txtSpeechToText.ReadOnly = false;

				btnSpeechToTextRecord.Text = "&Record";
				btnSpeechToTextRecord.Enabled = true;
			}
			catch (Exception ex)
			{
				BeepFail();

				string msg = $"Failed speech to text: {ex.Message}{Environment.NewLine}{ex.GetType().FullName}{Environment.NewLine}{ex.StackTrace}"; ;
				txtSpeechToText.Text = msg;
				txtSpeechToText.ReadOnly = false;

				btnSpeechToTextRecord.Text = "&Record";
				btnSpeechToTextRecord.Enabled = true;

				this.Activate();
				MessageBox.Show(this, msg, "Speech to text error", MessageBoxButtons.OK, MessageBoxIcon.Error);
			}
			finally
			{
				this._speechToTextState.AudioRecorderLock.Release();
			}
		}

		private static Hotkey MapHotKey(string hotKeyStringRepresentation)
		{
			var hotKey = new Hotkey();

			var keyStrings = hotKeyStringRepresentation.Split(@"_-+,;: ".ToCharArray(), StringSplitOptions.RemoveEmptyEntries)
				.Select(k => k.ToUpper())
				.ToList();
			string mainKeyString = keyStrings.Last();
			mainKeyString = NormalizeKeyString(mainKeyString);
			hotKey.KeyCode = Enum.Parse<Keys>(mainKeyString, true);

			if (keyStrings.Contains("ALT"))
				hotKey.Alt = true;
			if (keyStrings.Contains("CTRL") || keyStrings.Contains("CONTROL"))
				hotKey.Control = true;
			if (keyStrings.Contains("SHFT") || keyStrings.Contains("SHIFT"))
				hotKey.Shift = true;
			if (keyStrings.Contains("WIN") || keyStrings.Contains("WINDOWS") || keyStrings.Contains("START"))
				hotKey.Windows = true;

			return hotKey;
		}

		private static string NormalizeKeyString(string keyString)
		{
			keyString = keyString
				.Replace("{", "")
				.Replace("}", "");

			return keyString.ToLowerInvariant() switch
			{
				"del" => "delete",
				"ins" => "insert",
				_ => keyString
			};

		}

		private bool TryRegisterHotkey(Hotkey hotKey)
		{
			if (!hotKey.GetCanRegister(this))
			{
				this.Activate();
				MessageBox.Show($"Oops, looks like attempts to register the hotkey {hotKey} will fail or throw an exception.");
				return false;
			}
			else
			{
				hotKey.Register(this);
				return true;
			}
		}

		private void MutationForm_FormClosing(object sender, FormClosingEventArgs e)
		{
			_settings.MainWindowUiSettings.WindowSize = this.Size;
			_settings.MainWindowUiSettings.WindowLocation = this.Location;

			_settings.SpeetchToTextSettings.SpeechToTextPrompt = txtSpeechToTextPrompt.Text;
			_settings.LlmSettings.FormatTranscriptPrompt = txtFormatTranscriptPrompt.Text;
			_settings.LlmSettings.ReviewTranscriptPrompt = txtReviewTranscriptPrompt.Text;
			this._settingsManager.SaveSettingsToFile(_settings);

			UnregisterHotkey(_hkToggleMicMute);
			UnregisterHotkey(_hkOcr);
		}

		private static void UnregisterHotkey(Hotkey hk)
		{
			if (hk != null && hk.Registered)
				hk.Unregister();
		}

		private void MutationForm_Load(object sender, EventArgs e)
		{
			RestoreWindowLocationAndSizeFromSettings();

			txtSpeechToTextService.Text =
				$"{this._settings.SpeetchToTextSettings.Service}: {this._settings.SpeetchToTextSettings.ModelId}";
		}

		private async void btnSpeechToTextRecord_Click(object sender, EventArgs e)
		{
			await SpeechToText();
		}

		private void btnClearFormattedTranscript_Click(object sender, EventArgs e)
		{
			txtFormatTranscriptResponse.Text = string.Empty;
		}

		private async Task FormatSpeechToTextTranscriptWithRules()
		{
			string rawTranscript = txtSpeechToText.Text;

			string text = rawTranscript;
			if (radManualPunctuation.Checked)
			{
				text = text.RemoveSubstrings(",", ".", ";", ":", "?", "!", "...", "");
				text = text.Replace("  ", " ");
			}
			text = text.FormatWithRules(_settings.LlmSettings.TranscriptFormatRules);
			text = text.CleanupPunctuation();

			if (chkFormattedTranscriptAppend.Checked)
				txtFormatTranscriptResponse.Text += text;
			else
				txtFormatTranscriptResponse.Text = text;

			await Task.Delay(100);
			SetTextToClipboard(text);

			if (!this.ContainsFocus)
			{
				var selectedInsertOptionValue = cmbInsertInto3rdPartyApplication.SelectedItem;

				if (selectedInsertOptionValue is not null)
				{
					DictationInsertOption selectedOption = (DictationInsertOption)((dynamic)selectedInsertOptionValue).Value;

					switch (selectedOption)
					{
						case DictationInsertOption.SendKeys:
							BeepStart();
							System.Windows.Forms.SendKeys.Send(text);
							break;
						case DictationInsertOption.Paste:
							Thread.Sleep(200); // Wait for text to arrive on clipboard.
							BeepStart();
							System.Windows.Forms.SendKeys.SendWait("^v");
							break;
					}
				}
			}

			BeepSuccess();
		}

		private async Task FormatSpeechToTextTranscriptWithLlm()
		{
			txtFormatTranscriptResponse.Text = "Formatting...";
			BeepStart();

			string rawTranscript = txtSpeechToText.Text;
			string formatTranscriptPrompt = txtFormatTranscriptPrompt.Text;

			var messages = new List<ChatMessage>
			{
				ChatMessage.FromSystem($"{formatTranscriptPrompt}"),
				ChatMessage.FromUser($"Reformat the following transcript: {rawTranscript}"),
			};

			string formattedText = await _llmService.CreateChatCompletion(messages, Models.Gpt_4);
			txtFormatTranscriptResponse.Text = formattedText.FixNewLines();

			BeepSuccess();
		}

		private async Task ReviewSpeechToTextTranscriptWithLlm()
		{
			txtTranscriptReviewResponse.ReadOnly = true;
			txtTranscriptReviewResponse.Text = "Reviewing...";
			dgvReview.Enabled = false;
			SetReviewGridCaption("Reviewing...");

			dgvReview.Rows.Clear();
			BeepStart();

			string transcript = txtFormatTranscriptResponse.Text;
			string reviewTranscriptPrompt = txtReviewTranscriptPrompt.Text;

			var messages = new List<ChatMessage>
			{
				ChatMessage.FromSystem($"{reviewTranscriptPrompt}"),
				ChatMessage.FromUser($"Review the following transcript: {Environment.NewLine}{Environment.NewLine}{transcript}"),
			};

			var selectedTemperature = cmbReviewTemperature.SelectedItem;
			decimal temperature = ((dynamic)selectedTemperature).Value;
			string review = await _llmService.CreateChatCompletion(messages, Models.Gpt_4, temperature);
			txtTranscriptReviewResponse.Text = review.FixNewLines();
			txtTranscriptReviewResponse.ReadOnly = false;

			var lines = txtTranscriptReviewResponse.Text.Split(Environment.NewLine, StringSplitOptions.TrimEntries | StringSplitOptions.RemoveEmptyEntries);
			foreach (var line in lines)
			{
				string issue = line.RemovePrefix("- ");
				dgvReview.Rows.Add(new object[] { false, issue });
			}
			dgvReview.Enabled = true;
			SetReviewGridCaption("Issue");

			BeepSuccess();
		}

		private void SetReviewGridCaption(string text)
		{
			dgvReview.Columns[1].HeaderCell.Value = text;
		}

		private void BeepMuted()
		{
			Console.Beep(500, 200);
		}

		private void BeepUnmuted()
		{
			Console.Beep(1300, 50);
		}

		private static void BeepStart()
		{
			Console.Beep(970, 80);
		}

		private static void BeepSuccess()
		{
			Console.Beep(1050, 40);
			Console.Beep(1150, 40);
		}

		private static void BeepFail()
		{
			for (int i = 0; i < 3; i++)
				Console.Beep(300, 100);
		}

		private async void btnReviewTranscript_Click(object sender, EventArgs e)
		{
			await ReviewSpeechToTextTranscriptWithLlm();
		}

		private void lblFormatTranscriptPrompt_Click(object sender, EventArgs e)
		{
			txtFormatTranscriptPrompt.Visible = !txtFormatTranscriptPrompt.Visible;
		}

		private void lblReviewTranscriptPrompt_Click(object sender, EventArgs e)
		{
			txtReviewTranscriptPrompt.Visible = !txtReviewTranscriptPrompt.Visible;
		}

		private async void txtSpeechToText_TextChanged(object sender, EventArgs e)
		{
			if (!txtSpeechToText.ReadOnly)
			{
				await FormatSpeechToTextTranscriptWithRules();
			}
		}

		private void lblTranscriptReview_Click(object sender, EventArgs e)
		{
			dgvReview.Visible = txtTranscriptReviewResponse.Visible;
			txtTranscriptReviewResponse.Visible = !dgvReview.Visible;
		}

		private async void btnApplySelectedReviewIssues_Click(object sender, EventArgs e)
		{
			await ApplyReviewActionsToFormattedTranscriptWithLlm();
		}

		private async Task ApplyReviewActionsToFormattedTranscriptWithLlm()
		{
			List<(DataGridViewRow row, string instruction)> selectedRows = new();
			foreach (DataGridViewRow row in dgvReview.Rows)
			{
				if (row.Cells[0].Value != null && (bool)row.Cells[0].Value == true)
					selectedRows.Add((row, row.Cells[1].Value.ToString()));
			}

			if (selectedRows.Any())
			{
				txtFormatTranscriptResponse.ReadOnly = true;
				dgvReview.Enabled = false;
				SetReviewGridCaption("Applying corrections...");

				BeepStart();

				string transcript = txtFormatTranscriptResponse.Text;
				string systemPrompt = txtReviewTranscriptPrompt.Text;
				string[] instructions = selectedRows
					.Select(x => $"- {x.instruction}")
					.ToArray();
				string combinedInstructions = string.Join(Environment.NewLine, instructions);

				var messages = new List<ChatMessage>
				{
					ChatMessage.FromSystem($"{systemPrompt}"),
					ChatMessage.FromUser($"Apply the corrections and respond only with the corrected transcript.{Environment.NewLine}{Environment.NewLine}Correction Instructions:{Environment.NewLine}{combinedInstructions }{Environment.NewLine}{Environment.NewLine}Transcript:{Environment.NewLine}{transcript}"),
				};

				string revision = await _llmService.CreateChatCompletion(messages, Models.Gpt_4);
				txtFormatTranscriptResponse.Text = revision.FixNewLines();
				txtFormatTranscriptResponse.ReadOnly = false;

				foreach (var (row, instruction) in selectedRows)
					dgvReview.Rows.Remove(row);
				dgvReview.Enabled = true;
				SetReviewGridCaption("Issue");

				BeepSuccess();
			}
		}

		private void dgvReview_RowsAdded(object sender, DataGridViewRowsAddedEventArgs e)
		{

		}

		private void dgvReview_RowsRemoved(object sender, DataGridViewRowsRemovedEventArgs e)
		{

		}

		private void cmbActiveMicrophone_SelectedIndexChanged(object sender, EventArgs e)
		{
			var selectedItem = cmbActiveMicrophone.SelectedItem as CaptureDeviceComboItem;
			if (selectedItem is not null)
			{
				_microphone = selectedItem.CaptureDevice;
				SelectCaptureDeviceForNAudioBasedRecording();
				_settings.AudioSettings.ActiveCaptureDeviceFullName = _microphone.FullName;
				FeedbackMicrophoneStateToUser();
			}
			else
				MessageBox.Show($"Selected item is not a {nameof(CaptureDeviceComboItem)}.", "Selection Error", MessageBoxButtons.OK, MessageBoxIcon.Error);
		}
	}
}




